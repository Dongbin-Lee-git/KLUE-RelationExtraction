{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b741768a-d449-42f0-9290-da4f8964d7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import AutoTokenizer, XLMRobertaConfig, XLMRobertaTokenizer\n",
    "from transformers import XLMRobertaModel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from itertools import chain\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "import copy\n",
    "import csv\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import logging\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff82ea82-155f-4806-8da9-f101908fc89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed=42\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cdfb42c-1453-4e3c-895a-d182caddd437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 구성.\n",
    "class RE_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenized_dataset, labels):\n",
    "        self.tokenized_dataset = tokenized_dataset\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# 처음 불러온 tsv 파일을 원하는 형태의 DataFrame으로 변경 시켜줍니다.\n",
    "# 변경한 DataFrame 형태는 baseline code description 이미지를 참고해주세요.\n",
    "def preprocessing_dataset(dataset, label_type):\n",
    "    label = []\n",
    "    for i in dataset[8]:\n",
    "        if i == 'blind':\n",
    "            label.append(100)\n",
    "        else:\n",
    "            label.append(label_type[i])\n",
    "    out_dataset = pd.DataFrame({'sentence':dataset[1],'entity_01':dataset[2], 'e1s':dataset[3],'e1e':dataset[4],\n",
    "                              'entity_02':dataset[5], 'e2s':dataset[6],'e2e':dataset[7],'label':label})\n",
    "    return out_dataset\n",
    "\n",
    "# tsv 파일을 불러옵니다.\n",
    "def load_data(dataset_dir):\n",
    "  # load label_type, classes\n",
    "    with open('/opt/ml/input/data/label_type.pkl', 'rb') as f:\n",
    "        label_type = pickle.load(f)\n",
    "  # load dataset\n",
    "    dataset = pd.read_csv(dataset_dir, delimiter='\\t', header=None)\n",
    "  # preprecessing dataset\n",
    "    dataset = preprocessing_dataset(dataset, label_type)\n",
    "  \n",
    "    return dataset\n",
    "\n",
    "# XLMRoberta input을 위한 tokenizing.\n",
    "# tip! 다양한 종류의 tokenizer와 special token들을 활용하는 것으로도 새로운 시도를 해볼 수 있습니다.\n",
    "# baseline code에서는 2가지 부분을 활용했습니다.\n",
    "# def append_token(dataset, tokenizer):\n",
    "#     for (ex_index, example) in enumerate(dataset):\n",
    "        \n",
    "    \n",
    "\n",
    "def tokenized_dataset(dataset, tokenizer):\n",
    "    concat_entity = []\n",
    "    for e01, e02 in zip(dataset['entity_01'], dataset['entity_02']):\n",
    "        temp = ''\n",
    "        temp = e01 + '[SEP]' + e02\n",
    "        concat_entity.append(temp)\n",
    "        tokenized_sentences = tokenizer(\n",
    "      #concat_entity,\n",
    "          list(dataset['sentence']),\n",
    "          return_tensors=\"pt\",\n",
    "          padding=True,\n",
    "          truncation=True,\n",
    "          max_length=150,\n",
    "          add_special_tokens=True,\n",
    "          )\n",
    "    return tokenized_sentences\n",
    "\n",
    "def tokenized_dataset_len(dataset, tokenizer):\n",
    "    li = []\n",
    "    for sentence in dataset['sentence']:\n",
    "        li.append(tokenizer.tokenize(sentence))\n",
    "    return li\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6855113d-1ebe-4e5c-ba30-a10b5ef8b812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(preds, labels):\n",
    "    assert len(preds) == len(labels)\n",
    "    return acc_and_f1(preds, labels)\n",
    "\n",
    "\n",
    "def simple_accuracy(preds, labels):\n",
    "    return (preds == labels).mean()\n",
    "\n",
    "\n",
    "def official_f1():\n",
    "\n",
    "    with open(os.path.join('/opt/ml/eval/result.txt'), \"r\", encoding=\"utf-8\") as f:\n",
    "        macro_result = list(f)[-1]\n",
    "        macro_result = macro_result.split(\":\")[1].replace(\">>>\", \"\").strip()\n",
    "        macro_result = macro_result.split(\"=\")[1].strip().replace(\"%\", \"\")\n",
    "        macro_result = float(macro_result) / 100\n",
    "\n",
    "    return macro_result\n",
    "\n",
    "def acc_and_f1(preds, labels, average=\"macro\"):\n",
    "    acc = simple_accuracy(preds, labels)\n",
    "    return {\n",
    "        \"acc\": acc,\n",
    "        #\"f1\": official_f1(),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cff171a4-ad81-46e4-abe9-b019a4ef9c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sentence_to_features(train_dataset, tokenizer, max_len):\n",
    "    \n",
    "    max_seq_len=max_len\n",
    "    cls_token=tokenizer.cls_token\n",
    "    #cls_token_segment_id=tokenizer.cls_token_id\n",
    "    cls_token_segment_id=0\n",
    "    sep_token=tokenizer.sep_token\n",
    "    pad_token=1\n",
    "    pad_token_segment_id=0\n",
    "    sequence_a_segment_id=0\n",
    "    add_sep_token=False\n",
    "    mask_padding_with_zero=True\n",
    "    \n",
    "    all_input_ids = []\n",
    "    all_attention_mask = []\n",
    "    all_token_type_ids = []\n",
    "    all_e1_mask=[]\n",
    "    all_e2_mask=[]\n",
    "    all_label=[]\n",
    "    for idx in tqdm(range(len(train_dataset))):\n",
    "        if train_dataset['e1s'][idx] > train_dataset['e2s'][idx]:\n",
    "            train_dataset['sentence'][idx] = train_dataset['sentence'][idx][:train_dataset['e2s'][idx]] + ' <e2> ' + train_dataset['sentence'][idx][train_dataset['e2s'][idx]:train_dataset['e2e'][idx]+1] + ' </e2> ' + train_dataset['sentence'][idx][train_dataset['e2e'][idx]+1:train_dataset['e1s'][idx]] + ' <e1> ' + train_dataset['sentence'][idx][train_dataset['e1s'][idx]:train_dataset['e1e'][idx]+1] + ' </e1> ' + train_dataset['sentence'][idx][train_dataset['e1e'][idx]+1:]\n",
    "        else:\n",
    "            train_dataset['sentence'][idx] = train_dataset['sentence'][idx][:train_dataset['e1s'][idx]] + ' <e1> ' + train_dataset['sentence'][idx][train_dataset['e1s'][idx]:train_dataset['e1e'][idx]+1] + ' </e1> ' + train_dataset['sentence'][idx][train_dataset['e1e'][idx]+1:train_dataset['e2s'][idx]] + ' <e2> ' + train_dataset['sentence'][idx][train_dataset['e2s'][idx]:train_dataset['e2e'][idx]+1] + ' </e2> ' + train_dataset['sentence'][idx][train_dataset['e2e'][idx]+1:]    \n",
    "\n",
    "        \n",
    "        token = tokenizer.tokenize(train_dataset['sentence'][idx])\n",
    "        \n",
    "        e11_p = token.index(\"<e1>\")  # the start position of entity1\n",
    "        e12_p = token.index(\"</e1>\")  # the end position of entity1\n",
    "        e21_p = token.index(\"<e2>\")  # the start position of entity2\n",
    "        e22_p = token.index(\"</e2>\")  # the end position of entity2\n",
    "\n",
    "        token[e11_p] = \"$\"\n",
    "        token[e12_p] = \"$\"\n",
    "        token[e21_p] = \"#\"\n",
    "        token[e22_p] = \"#\"\n",
    "\n",
    "        #print(token)\n",
    "\n",
    "        e11_p += 1\n",
    "        e12_p += 1\n",
    "        e21_p += 1\n",
    "        e22_p += 1\n",
    "\n",
    "        special_tokens_count = 1\n",
    "\n",
    "        if len(token) < max_seq_len - special_tokens_count:\n",
    "#            token = token[: (max_seq_len - special_tokens_count)]\n",
    "\n",
    "#         if add_sep_token:\n",
    "#             token += [sep_token]\n",
    "\n",
    "            token_type_ids = [sequence_a_segment_id] * len(token)\n",
    "\n",
    "            token = [cls_token] + token \n",
    "            token_type_ids = [cls_token_segment_id] + token_type_ids\n",
    "\n",
    "            input_ids = tokenizer.convert_tokens_to_ids(token)\n",
    "\n",
    "            attention_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
    "\n",
    "            padding_length = max_seq_len - len(input_ids)\n",
    "            input_ids = input_ids + ([pad_token] * padding_length)\n",
    "            attention_mask = attention_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\n",
    "            token_type_ids = token_type_ids + ([pad_token_segment_id] * padding_length)\n",
    "\n",
    "            e1_mask = [0] * len(attention_mask)\n",
    "            e2_mask = [0] * len(attention_mask)\n",
    "\n",
    "            for i in range(e11_p, e12_p + 1):\n",
    "                e1_mask[i] = 1\n",
    "            for i in range(e21_p, e22_p + 1):\n",
    "                e2_mask[i] = 1\n",
    "\n",
    "            assert len(input_ids) == max_seq_len, \"Error with input length {} vs {}\".format(len(input_ids), max_seq_len)\n",
    "            assert len(attention_mask) == max_seq_len, \"Error with attention mask length {} vs {}\".format(\n",
    "                len(attention_mask), max_seq_len\n",
    "            )\n",
    "            assert len(token_type_ids) == max_seq_len, \"Error with token type length {} vs {}\".format(\n",
    "                len(token_type_ids), max_seq_len\n",
    "            )\n",
    "\n",
    "            all_input_ids.append(input_ids)\n",
    "            all_attention_mask.append(attention_mask)\n",
    "            all_token_type_ids.append(token_type_ids)\n",
    "            all_e1_mask.append(e1_mask)\n",
    "            all_e2_mask.append(e2_mask)\n",
    "            all_label.append(train_dataset['label'][idx])\n",
    "    \n",
    "    all_features = {\n",
    "        'input_ids' : torch.tensor(all_input_ids),\n",
    "        'attention_mask' : torch.tensor(all_attention_mask),\n",
    "        'token_type_ids' : torch.tensor(all_token_type_ids),\n",
    "        'e1_mask' : torch.tensor(all_e1_mask),\n",
    "        'e2_mask' : torch.tensor(all_e2_mask)\n",
    "    }  \n",
    "    return RE_Dataset(all_features, all_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6fa607d-195f-428d-a722-c6e6c1bd8aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_loss(loss, reduction='mean'):\n",
    "    return loss.mean() if reduction=='mean' else loss.sum() if reduction=='sum' else loss\n",
    "\n",
    "# Implementation from fastai https://github.com/fastai/fastai2/blob/master/fastai2/layers.py#L338\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, e:float=0.05, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.e,self.reduction = e,reduction\n",
    "    \n",
    "    def forward(self, output, target):\n",
    "        # number of classes\n",
    "        c = output.size()[-1]\n",
    "        log_preds = F.log_softmax(output, dim=-1)\n",
    "        loss = reduce_loss(-log_preds.sum(dim=-1), self.reduction)\n",
    "        nll = F.nll_loss(log_preds, target, reduction=self.reduction)\n",
    "        # (1-ε)* H(q,p) + ε*H(u,p)\n",
    "        return (1-self.e)*nll + self.e*(loss/c) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12ef695e-bb2b-4046-a7f6-61c8c63194f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "class Cross_FocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None,\n",
    "    gamma=2., reduction='mean', **kwargs):\n",
    "\n",
    "        nn.Module.__init__(self)\n",
    "        self.weight=weight\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "    \n",
    "    def forward(self, inputs,targets):\n",
    "\n",
    "        loss_fct_cross = nn.CrossEntropyLoss()\n",
    "        loss_cross = loss_fct_cross(inputs, targets)\n",
    "\n",
    "        loss_fct_focal = FocalLoss()\n",
    "        loss_focal = loss_fct_focal(inputs, targets)\n",
    "\n",
    "        # 두 비율이 합쳐서 1이 되야함\n",
    "        cross_rate = 0.75\n",
    "        focal_rate = 0.25\n",
    "\n",
    "        return loss_cross*cross_rate +loss_focal*focal_rate\n",
    "\n",
    "class FocalLoss(nn.modules.loss._WeightedLoss):\n",
    "    def __init__(self, weight=None, gamma=2,reduction='mean'):\n",
    "        super(FocalLoss, self).__init__(weight,reduction=reduction)\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight #weight parameter will act as the alpha parameter to balance class weights\n",
    "\n",
    "    def forward(self, input, target):\n",
    "\n",
    "        ce_loss = F.cross_entropy(input, target,reduction=self.reduction,weight=self.weight) \n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = ((1 - pt) ** self.gamma * ce_loss).mean()\n",
    "        return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a25068cb-7a20-49fc-8972-7e18830dd6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_rate=0.0, use_activation=True):\n",
    "        super(FCLayer, self).__init__()\n",
    "        self.use_activation = use_activation\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        if self.use_activation:\n",
    "            x = self.tanh(x)\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "class RXLMRoberta(XLMRobertaModel):\n",
    "    def __init__(self,  model_name, config, dropout_rate):\n",
    "        super(RXLMRoberta, self).__init__(config)\n",
    "        self.XLMRoberta = XLMRobertaModel.from_pretrained(model_name, config=config)  # Load pretrained XLMRoberta\n",
    "\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.cls_fc_layer = FCLayer(config.hidden_size, config.hidden_size, dropout_rate)\n",
    "        self.entity_fc_layer1 = FCLayer(config.hidden_size, config.hidden_size, dropout_rate)\n",
    "        self.entity_fc_layer2 = FCLayer(config.hidden_size, config.hidden_size, dropout_rate)\n",
    "\n",
    "        self.label_classifier = FCLayer(\n",
    "            config.hidden_size * 3,\n",
    "            config.num_labels,\n",
    "            dropout_rate,\n",
    "            use_activation=False,\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def entity_average(hidden_output, e_mask):\n",
    "        \"\"\"\n",
    "        Average the entity hidden state vectors (H_i ~ H_j)\n",
    "        :param hidden_output: [batch_size, j-i+1, dim]\n",
    "        :param e_mask: [batch_size, max_seq_len]\n",
    "                e.g. e_mask[0] == [0, 0, 0, 1, 1, 1, 0, 0, ... 0]\n",
    "        :return: [batch_size, dim]\n",
    "        \"\"\"\n",
    "        e_mask_unsqueeze = e_mask.unsqueeze(1)  # [b, 1, j-i+1]\n",
    "        length_tensor = (e_mask != 0).sum(dim=1).unsqueeze(1)  # [batch_size, 1]\n",
    "\n",
    "        # [b, 1, j-i+1] * [b, j-i+1, dim] = [b, 1, dim] -> [b, dim]\n",
    "        sum_vector = torch.bmm(e_mask_unsqueeze.float(), hidden_output).squeeze(1)\n",
    "        avg_vector = sum_vector.float() / length_tensor.float()  # broadcasting\n",
    "        return avg_vector\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, labels, e1_mask, e2_mask):\n",
    "        outputs = self.XLMRoberta(\n",
    "            input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids\n",
    "        )  # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "        sequence_output = outputs[0]\n",
    "        pooled_output = outputs[1]  # [CLS]\n",
    "    \n",
    "        e1_h = self.entity_average(sequence_output, e1_mask)\n",
    "        e2_h = self.entity_average(sequence_output, e2_mask)\n",
    "        # Dropout -> tanh -> fc_layer (Share FC layer for e1 and e2)\n",
    "        pooled_output = self.cls_fc_layer(pooled_output)\n",
    "        e1_h = self.entity_fc_layer1(e1_h)\n",
    "        e2_h = self.entity_fc_layer2(e2_h)\n",
    "        # Concat -> fc_layer\n",
    "        #concat_h = torch.cat([pooled_output, e1_h, e2_h, torch.abs(torch.sub(e1_h,e2_h))], dim=-1)\n",
    "        concat_h = torch.cat([pooled_output, e1_h, e2_h], dim=-1)\n",
    "        logits = self.label_classifier(concat_h)\n",
    "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
    "        # Softmax\n",
    "        if labels is not None:\n",
    "            if self.num_labels == 1:\n",
    "                loss_fct = nn.MSELoss()\n",
    "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "            else:\n",
    "                #loss_fct = nn.CrossEntropyLoss()\n",
    "                #loss_fct = LabelSmoothingCrossEntropy()\n",
    "                loss_fct = Cross_FocalLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "            outputs = (loss,) + outputs\n",
    "\n",
    "        return outputs  # (loss), logits, (hidden_states), (attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0765d127-ca15-47ef-a8d1-df6fd1530e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14e99d0c-e953-41a0-a38e-87c51f6ba795",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "class Trainer(object):\n",
    "    def __init__(self,num_labels, label_dict,logging_steps, save_steps,max_steps,\n",
    "                 num_train_epochs,warmup_steps,adam_epsilon,learning_rate,gradient_accumulation_steps,\n",
    "                 max_grad_norm, eval_batch_size, train_batch_size, model_dir, dropout_rate, classifier_epoch,\n",
    "                 weight_decay, Model_name ,train_dataset=None, dev_dataset=None, test_dataset=None):\n",
    "        #self.args = args\n",
    "        self.train_dataset = train_dataset\n",
    "        self.eval_batch_size = eval_batch_size\n",
    "        self.train_batch_size = train_batch_size\n",
    "        self.dev_dataset = dev_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "        self.Model_name = Model_name\n",
    "        self.label_lst = label_dict\n",
    "        self.num_labels = num_labels\n",
    "        self.max_steps = max_steps\n",
    "        self.weight_decay = weight_decay\n",
    "        self.learning_rate = learning_rate\n",
    "        self.adam_epsilon=adam_epsilon\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.num_train_epochs = num_train_epochs\n",
    "        self.logging_steps = logging_steps\n",
    "        self.save_steps = save_steps\n",
    "        self.max_grad_norm = max_grad_norm\n",
    "        self.model_dir = model_dir\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.classifier_epoch=classifier_epoch\n",
    "        self.gradient_accumulation_steps = gradient_accumulation_steps\n",
    "        self.global_epo=0\n",
    "        self.config = XLMRobertaConfig.from_pretrained(\n",
    "            self.Model_name,\n",
    "            num_labels=self.num_labels,\n",
    "            #id2label={str(i): label for i, label in enumerate(self.label_lst)},\n",
    "            id2label=self.label_lst,\n",
    "            #label2id={label: i for key, label in self.label_lst},\n",
    "            label2id={value : key for key, value in self.label_lst.items()}\n",
    "        )\n",
    "        self.model = RXLMRoberta(\n",
    "            self.Model_name, config=self.config, dropout_rate = self.dropout_rate,\n",
    "        )\n",
    "\n",
    "        # GPU or CPU\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def train(self):\n",
    "        train_sampler = RandomSampler(self.train_dataset)\n",
    "        train_dataloader = DataLoader(\n",
    "            self.train_dataset,\n",
    "            sampler=train_sampler,\n",
    "            batch_size=self.train_batch_size,\n",
    "        )\n",
    "\n",
    "        if self.max_steps > 0:\n",
    "            t_total = self.max_steps\n",
    "            self.num_train_epochs = (\n",
    "                self.max_steps // (len(train_dataloader) // self.gradient_accumulation_steps) + 1\n",
    "            )\n",
    "        else:\n",
    "            t_total = len(train_dataloader) // self.gradient_accumulation_steps * self.num_train_epochs\n",
    "\n",
    "        # Prepare optimizer and schedule (linear warmup and decay)\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in self.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": self.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = AdamW(\n",
    "            optimizer_grouped_parameters,\n",
    "            lr=self.learning_rate,\n",
    "            eps=self.adam_epsilon,\n",
    "        )\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=self.warmup_steps,\n",
    "            num_training_steps=t_total,\n",
    "        )\n",
    "        \n",
    "        #scaler = torch.cuda.amp.GradScaler()\n",
    "        # Train!\n",
    "        logger.info(\"***** Running training *****\")\n",
    "        logger.info(\"  Num examples = %d\", len(self.train_dataset))\n",
    "        logger.info(\"  Num Epochs = %d\", self.num_train_epochs)\n",
    "        logger.info(\"  Total train batch size = %d\", self.train_batch_size)\n",
    "        logger.info(\"  Gradient Accumulation steps = %d\", self.gradient_accumulation_steps)\n",
    "        logger.info(\"  Total optimization steps = %d\", t_total)\n",
    "        logger.info(\"  Logging steps = %d\", self.logging_steps)\n",
    "        logger.info(\"  Save steps = %d\", self.save_steps)\n",
    "\n",
    "        global_step = 0\n",
    "        tr_loss = 0.0\n",
    "        self.model.zero_grad()\n",
    "\n",
    "        train_iterator = tqdm(range(int(self.num_train_epochs)), desc=\"Epoch\")\n",
    "\n",
    "        for epo_step in train_iterator:\n",
    "            self.global_epo = epo_step\n",
    "            epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\")\n",
    "            for step, batch in enumerate(epoch_iterator):\n",
    "                self.model.train()\n",
    "                batch = tuple(batch[t].to(self.device) for t in batch)  # GPU or CPU\n",
    "                inputs = {\n",
    "                    \"input_ids\": batch[0],\n",
    "                    \"attention_mask\": batch[1],\n",
    "                    \"token_type_ids\" : batch[2],\n",
    "                    \"labels\": batch[5],\n",
    "                    \"e1_mask\": batch[3],\n",
    "                    \"e2_mask\": batch[4]\n",
    "                }\n",
    "                #with torch.cuda.amp.autocast():\n",
    "                outputs = self.model(**inputs)\n",
    "                loss = outputs[0]\n",
    "\n",
    "                if self.gradient_accumulation_steps > 1:\n",
    "                    loss = loss / self.gradient_accumulation_steps\n",
    "\n",
    "                #scaler.scale(loss).backward()\n",
    "                loss.backward()\n",
    "\n",
    "                tr_loss += loss.item()\n",
    "                if (step + 1) % self.gradient_accumulation_steps == 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)\n",
    "\n",
    "                    optimizer.step()\n",
    "                    #scaler.step(optimizer)\n",
    "                    #scaler.update()\n",
    "                    scheduler.step()  # Update learning rate schedule\n",
    "                    self.model.zero_grad()\n",
    "                    global_step += 1\n",
    "\n",
    "                    if self.logging_steps > 0 and global_step % self.logging_steps == 0:\n",
    "                        logger.info(\"  global steps = %d\", global_step)\n",
    "                        self.evaluate(\"train\")  # There is no dev set for semeval task\n",
    "\n",
    "                    if self.save_steps > 0 and global_step % self.save_steps == 0:\n",
    "                        self.save_model()\n",
    "\n",
    "                if 0 < self.max_steps < global_step:\n",
    "                    epoch_iterator.close()\n",
    "                    break\n",
    "\n",
    "            if 0 < self.max_steps < global_step:\n",
    "                train_iterator.close()\n",
    "                break\n",
    "\n",
    "        return global_step, tr_loss / global_step\n",
    "    \n",
    "   \n",
    "    def evaluate(self, mode):\n",
    "        # We use test dataset because semeval doesn't have dev dataset\n",
    "        if mode == \"test\":\n",
    "            dataset = self.test_dataset\n",
    "        elif mode == \"dev\":\n",
    "            dataset = self.dev_dataset\n",
    "        elif mode == \"train\":\n",
    "            dataset = self.train_dataset\n",
    "        else:\n",
    "            raise Exception(\"Only dev and test dataset available\")\n",
    "\n",
    "        eval_sampler = SequentialSampler(dataset)\n",
    "        eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=self.eval_batch_size)\n",
    "\n",
    "        # Eval!\n",
    "        logger.info(\"***** Running evaluation on %s dataset *****\", mode)\n",
    "        logger.info(\"  Num examples = %d\", len(dataset))\n",
    "        logger.info(\"  Batch size = %d\", self.eval_batch_size)\n",
    "        eval_loss = 0.0\n",
    "        nb_eval_steps = 0\n",
    "        preds = None\n",
    "        out_label_ids = None\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "            batch = tuple(batch[t].to(self.device) for t in batch)\n",
    "            with torch.no_grad():\n",
    "                inputs = {\n",
    "                    \"input_ids\": batch[0],\n",
    "                    \"attention_mask\": batch[1],\n",
    "                    \"token_type_ids\": batch[2],\n",
    "                    \"labels\": batch[5],\n",
    "                    \"e1_mask\": batch[3],\n",
    "                    \"e2_mask\": batch[4],\n",
    "                }\n",
    "                #with torch.cuda.amp.autocast():\n",
    "                outputs = self.model(**inputs)\n",
    "                tmp_eval_loss, logits = outputs[:2]\n",
    "                eval_loss += tmp_eval_loss.mean().item()\n",
    "            nb_eval_steps += 1\n",
    "\n",
    "            if preds is None:\n",
    "                preds = logits.detach().cpu().numpy()\n",
    "                out_label_ids = inputs[\"labels\"].detach().cpu().numpy()\n",
    "            else:\n",
    "                preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "                out_label_ids = np.append(out_label_ids, inputs[\"labels\"].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "        eval_loss = eval_loss / nb_eval_steps\n",
    "        results = {\"loss\": eval_loss}\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "\n",
    "        result = compute_metrics(preds, out_label_ids)\n",
    "        results.update(result)\n",
    "\n",
    "        logger.info(\"***** Eval results *****\")\n",
    "        for key in sorted(results.keys()):\n",
    "            logger.info(\"  {} = {:.4f}\".format(key, results[key]))\n",
    "            if key == 'acc':\n",
    "                if results[key] > 0.85:\n",
    "                    self.test_pred()\n",
    "        return results\n",
    "    \n",
    "    def test_pred(self):\n",
    "        test_dataset = self.test_dataset\n",
    "        test_sampler = SequentialSampler(test_dataset)\n",
    "        test_dataloader = DataLoader(test_dataset, sampler=test_sampler,batch_size=self.eval_batch_size)\n",
    "\n",
    "        # Eval!\n",
    "        logger.info(\"***** Running evaluation on %s dataset *****\", \"test\")\n",
    "        #logger.info(\"  Num examples = %d\", len(dataset))\n",
    "        logger.info(\"  Batch size = %d\", self.eval_batch_size)\n",
    "\n",
    "        nb_eval_steps = 0\n",
    "        preds = None\n",
    "        out_label_ids = None\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        for batch in tqdm(test_dataloader, desc=\"Predicting\"):\n",
    "            batch = tuple(batch[t].to(self.device) for t in batch)\n",
    "            with torch.no_grad():\n",
    "                inputs = {\n",
    "                    \"input_ids\": batch[0],\n",
    "                    \"attention_mask\": batch[1],\n",
    "                    \"token_type_ids\": batch[2],\n",
    "                    \"labels\": None,\n",
    "                    \"e1_mask\": batch[3],\n",
    "                    \"e2_mask\": batch[4],\n",
    "                }\n",
    "                outputs = self.model(**inputs)\n",
    "                #print(outputs)\n",
    "                pred = outputs[0]\n",
    "\n",
    "            nb_eval_steps += 1\n",
    "\n",
    "            if preds is None:\n",
    "                preds = pred.detach().cpu().numpy()\n",
    "                #out_label_ids = inputs[\"labels\"].detach().cpu().numpy()\n",
    "            else:\n",
    "                preds = np.append(preds, pred.detach().cpu().numpy(), axis=0)\n",
    "                #out_label_ids = np.append(out_label_ids, inputs[\"labels\"].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "        df = pd.DataFrame(preds, columns=['pred'])\n",
    "        df.to_csv('RXLMRoberta_layersplit_with_focalcross_epoch'+str(self.global_epo)+'.csv', index=False)\n",
    "#         with open(\"proposed_answers.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "#             for idx, pred in enumerate(preds):\n",
    "#                 f.write(\"{}\\n\".format(pred))\n",
    "        #write_prediction(self.args, os.path.join(self.args.eval_dir, \"proposed_answers.txt\"), preds)\n",
    "    \n",
    "\n",
    "    def save_model(self):\n",
    "        # Save model checkpoint (Overwrite)\n",
    "        if not os.path.exists(self.model_dir):\n",
    "            os.makedirs(self.model_dir)\n",
    "        model_to_save = self.model.module if hasattr(self.model, \"module\") else self.model\n",
    "        model_to_save.save_pretrained(self.model_dir)\n",
    "\n",
    "        # Save training arguments together with the trained model\n",
    "        #torch.save(self.args, os.path.join(self.args.model_dir, \"training_args.bin\"))\n",
    "        logger.info(\"Saving model checkpoint to %s\", self.model_dir)\n",
    "\n",
    "    def load_model(self):\n",
    "        # Check whether model exists\n",
    "        if not os.path.exists(self.model_dir):\n",
    "            raise Exception(\"Model doesn't exists! Train first!\")\n",
    "\n",
    "        #self.args = torch.load(os.path.join(self.args.model_dir, \"training_args.bin\"))\n",
    "        self.model = RXLMRoberta.from_pretrained(self.model_dir)\n",
    "        self.model.to(self.device)\n",
    "        logger.info(\"***** Model Loaded *****\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdf1565f-1a5a-4def-9b07-b7a8d3611cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_logger():\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc40c6f-54df-444c-89c1-d4ac70d453a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = load_data(\"/opt/ml/input/data/train/train.tsv\")\n",
    "# test_dataset = load_data(\"/opt/ml/input/data/test/test.tsv\")\n",
    "# #dev_dataset = load_data(\"./dataset/train/dev.tsv\")\n",
    "# #train_label = train_dataset['label'].values\n",
    "# #train_dataset.columns= ['link','sentence' 'entity_01','e1s','e1e','entity_02','e2s','e2e','label']\n",
    "# ADDITIONAL_SPECIAL_TOKENS = [\"<e1>\", \"</e1>\", \"<e2>\", \"</e2>\"]\n",
    "# MODEL_NAME = \"xlm-roberta-large\"\n",
    "# #MODEL_NAME = \"xlm-roXLMRobertaa-large\"\n",
    "# tokenizer = XLMRobertaTokenizer.from_pretrained(MODEL_NAME)\n",
    "# tokenizer.add_special_tokens({\"additional_special_tokens\": ADDITIONAL_SPECIAL_TOKENS})\n",
    "# train_Dataset = convert_sentence_to_features(train_dataset, tokenizer, max_len = 339+2)\n",
    "# print(train_Dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9dc1b1-76c8-4757-aa34-cf17e66a1a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_NAME = \"xlm-roberta-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "print(tokenizer(['안녕 만나서 반가워', '왜 이게 이렇게 나오지'],\n",
    "      return_tensors=\"pt\",\n",
    "      padding=True,\n",
    "      truncation=True,\n",
    "      max_length=100,\n",
    "      add_special_tokens=True,\n",
    "      return_token_type_ids=True,\n",
    "      ))\n",
    "ADDITIONAL_SPECIAL_TOKENS = [\"<e1>\", \"</e1>\", \"<e2>\", \"</e2>\"]\n",
    "      \n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\": ADDITIONAL_SPECIAL_TOKENS})\n",
    "train_Dataset = convert_sentence_to_features(['안녕 만나서 반가워', '왜 이게 이렇게 나오지'], tokenizer, max_len = 339+2)\n",
    "\n",
    "print(tokenizer.pad_token, tokenizer.pad_token_id)\n",
    "print(tokenizer.cls_token, tokenizer.cls_token_id)\n",
    "print(tokenizer.sep_token, tokenizer.sep_token_id)\n",
    "# load dataset\n",
    "train_dataset = load_data(\"/opt/ml/input/data/train/train.tsv\")\n",
    "#dev_dataset = load_data(\"./dataset/train/dev.tsv\")\n",
    "train_label = train_dataset['label'].values\n",
    "#dev_label = dev_dataset['label'].values\n",
    "\n",
    "\n",
    "tokenized_len_dataset = tokenized_dataset_len(train_dataset, tokenizer)\n",
    "print('최대 길이 : ', max(len(i) for i in tokenized_len_dataset))\n",
    "print('평균 길이 : ', sum(map(len, tokenized_len_dataset))/len(tokenized_len_dataset))\n",
    "plt.hist([len(s) for s in tokenized_len_dataset], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c16c05-f3bd-451c-9c6e-1ab30da8295e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"xlm-roberta-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "ADDITIONAL_SPECIAL_TOKENS = [\"<e1>\", \"</e1>\", \"<e2>\", \"</e2>\"] \n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\": ADDITIONAL_SPECIAL_TOKENS})\n",
    "\n",
    "train_dataset = load_data(\"/opt/ml/input/data/train/train.tsv\")\n",
    "train_label = train_dataset['label'].values\n",
    "\n",
    "for idx in tqdm(range(len(train_dataset))):\n",
    "    if train_dataset['e1s'][idx] > train_dataset['e2s'][idx]:\n",
    "        train_dataset['sentence'][idx] = train_dataset['sentence'][idx][:train_dataset['e2s'][idx]] + ' <e2> ' + train_dataset['sentence'][idx][train_dataset['e2s'][idx]:train_dataset['e2e'][idx]+1] + ' </e2> ' + train_dataset['sentence'][idx][train_dataset['e2e'][idx]+1:train_dataset['e1s'][idx]] + ' <e1> ' + train_dataset['sentence'][idx][train_dataset['e1s'][idx]:train_dataset['e1e'][idx]+1] + ' </e1> ' + train_dataset['sentence'][idx][train_dataset['e1e'][idx]+1:]          \n",
    "    else:\n",
    "        train_dataset['sentence'][idx] = train_dataset['sentence'][idx][:train_dataset['e1s'][idx]] + ' <e1> ' + train_dataset['sentence'][idx][train_dataset['e1s'][idx]:train_dataset['e1e'][idx]+1] + ' </e1> ' + train_dataset['sentence'][idx][train_dataset['e1e'][idx]+1:train_dataset['e2s'][idx]] + ' <e2> ' + train_dataset['sentence'][idx][train_dataset['e2s'][idx]:train_dataset['e2e'][idx]+1] + ' </e2> ' + train_dataset['sentence'][idx][train_dataset['e2e'][idx]+1:]              \n",
    "\n",
    "\n",
    "tokenized_len_dataset = tokenized_dataset_len(train_dataset, tokenizer)\n",
    "\n",
    "print('최대 길이 : ', max(len(i) for i in tokenized_len_dataset))\n",
    "print('평균 길이 : ', sum(map(len, tokenized_len_dataset))/len(tokenized_len_dataset))\n",
    "plt.hist([len(s) for s in tokenized_len_dataset], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3bab54-a7da-4d1f-ac47-36b69bdfd32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"xlm-roberta-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "ADDITIONAL_SPECIAL_TOKENS = [\"<e1>\", \"</e1>\", \"<e2>\", \"</e2>\"] \n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\": ADDITIONAL_SPECIAL_TOKENS})\n",
    "\n",
    "train_dataset = load_data(\"/opt/ml/input/data/train/train.tsv\")\n",
    "li = [len(i) for i in tokenized_len_dataset]\n",
    "train_dataset['len'] = li\n",
    "\n",
    "train_dataset = train_dataset[train_dataset['len'] <= 250]\n",
    "train_dataset = train_dataset.reset_index(drop=False, inplace=False)\n",
    "del train_dataset['index']\n",
    "#train_dataset.head(57)\n",
    "#train_dataset.head()\n",
    "for idx in tqdm(range(len(train_dataset))):\n",
    "    if train_dataset['e1s'][idx] > train_dataset['e2s'][idx]:\n",
    "        train_dataset['sentence'][idx] = train_dataset['sentence'][idx][:train_dataset['e2s'][idx]] + ' <e2> ' + train_dataset['sentence'][idx][train_dataset['e2s'][idx]:train_dataset['e2e'][idx]+1] + ' </e2> ' + train_dataset['sentence'][idx][train_dataset['e2e'][idx]+1:train_dataset['e1s'][idx]] + ' <e1> ' + train_dataset['sentence'][idx][train_dataset['e1s'][idx]:train_dataset['e1e'][idx]+1] + ' </e1> ' + train_dataset['sentence'][idx][train_dataset['e1e'][idx]+1:]          \n",
    "    else:\n",
    "        train_dataset['sentence'][idx] = train_dataset['sentence'][idx][:train_dataset['e1s'][idx]] + ' <e1> ' + train_dataset['sentence'][idx][train_dataset['e1s'][idx]:train_dataset['e1e'][idx]+1] + ' </e1> ' + train_dataset['sentence'][idx][train_dataset['e1e'][idx]+1:train_dataset['e2s'][idx]] + ' <e2> ' + train_dataset['sentence'][idx][train_dataset['e2s'][idx]:train_dataset['e2e'][idx]+1] + ' </e2> ' + train_dataset['sentence'][idx][train_dataset['e2e'][idx]+1:]              \n",
    "\n",
    "\n",
    "tokenized_len_dataset = tokenized_dataset_len(train_dataset, tokenizer)\n",
    "\n",
    "print('최대 길이 : ', max(len(i) for i in tokenized_len_dataset))\n",
    "print('평균 길이 : ', sum(map(len, tokenized_len_dataset))/len(tokenized_len_dataset))\n",
    "plt.hist([len(s) for s in tokenized_len_dataset], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bbce9a-f2ef-4049-8ecd-7e52c26f713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"xlm-roberta-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "ADDITIONAL_SPECIAL_TOKENS = [\"<e1>\", \"</e1>\", \"<e2>\", \"</e2>\"] \n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\": ADDITIONAL_SPECIAL_TOKENS})\n",
    "\n",
    "train_dataset = load_data(\"/opt/ml/input/data/test/test.tsv\")\n",
    "train_label = train_dataset['label'].values\n",
    "\n",
    "for idx in tqdm(range(len(train_dataset))):\n",
    "    if train_dataset['e1s'][idx] > train_dataset['e2s'][idx]:\n",
    "        train_dataset['sentence'][idx] = train_dataset['sentence'][idx][:train_dataset['e2s'][idx]] + ' <e2> ' + train_dataset['sentence'][idx][train_dataset['e2s'][idx]:train_dataset['e2e'][idx]+1] + ' </e2> ' + train_dataset['sentence'][idx][train_dataset['e2e'][idx]+1:train_dataset['e1s'][idx]] + ' <e1> ' + train_dataset['sentence'][idx][train_dataset['e1s'][idx]:train_dataset['e1e'][idx]+1] + ' </e1> ' + train_dataset['sentence'][idx][train_dataset['e1e'][idx]+1:]          \n",
    "    else:\n",
    "        train_dataset['sentence'][idx] = train_dataset['sentence'][idx][:train_dataset['e1s'][idx]] + ' <e1> ' + train_dataset['sentence'][idx][train_dataset['e1s'][idx]:train_dataset['e1e'][idx]+1] + ' </e1> ' + train_dataset['sentence'][idx][train_dataset['e1e'][idx]+1:train_dataset['e2s'][idx]] + ' <e2> ' + train_dataset['sentence'][idx][train_dataset['e2s'][idx]:train_dataset['e2e'][idx]+1] + ' </e2> ' + train_dataset['sentence'][idx][train_dataset['e2e'][idx]+1:]              \n",
    "\n",
    "\n",
    "tokenized_len_dataset = tokenized_dataset_len(train_dataset, tokenizer)\n",
    "print('최대 길이 : ', max(len(i) for i in tokenized_len_dataset))\n",
    "print('평균 길이 : ', sum(map(len, tokenized_len_dataset))/len(tokenized_len_dataset))\n",
    "plt.hist([len(s) for s in tokenized_len_dataset], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6221073-169e-49c2-b58e-857d67e9bb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"xlm-roberta-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "ADDITIONAL_SPECIAL_TOKENS = [\"<e1>\", \"</e1>\", \"<e2>\", \"</e2>\"] \n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\": ADDITIONAL_SPECIAL_TOKENS})\n",
    "\n",
    "train_dataset = load_data(\"/opt/ml/input/data/train/train+all.tsv\")\n",
    "train_label = train_dataset['label'].values\n",
    "\n",
    "for idx in tqdm(range(len(train_dataset))):\n",
    "    if train_dataset['e1s'][idx] > train_dataset['e2s'][idx]:\n",
    "        train_dataset['sentence'][idx] = train_dataset['sentence'][idx][:train_dataset['e2s'][idx]] + ' <e2> ' + train_dataset['sentence'][idx][train_dataset['e2s'][idx]:train_dataset['e2e'][idx]+1] + ' </e2> ' + train_dataset['sentence'][idx][train_dataset['e2e'][idx]+1:train_dataset['e1s'][idx]] + ' <e1> ' + train_dataset['sentence'][idx][train_dataset['e1s'][idx]:train_dataset['e1e'][idx]+1] + ' </e1> ' + train_dataset['sentence'][idx][train_dataset['e1e'][idx]+1:]          \n",
    "    else:\n",
    "        train_dataset['sentence'][idx] = train_dataset['sentence'][idx][:train_dataset['e1s'][idx]] + ' <e1> ' + train_dataset['sentence'][idx][train_dataset['e1s'][idx]:train_dataset['e1e'][idx]+1] + ' </e1> ' + train_dataset['sentence'][idx][train_dataset['e1e'][idx]+1:train_dataset['e2s'][idx]] + ' <e2> ' + train_dataset['sentence'][idx][train_dataset['e2s'][idx]:train_dataset['e2e'][idx]+1] + ' </e2> ' + train_dataset['sentence'][idx][train_dataset['e2e'][idx]+1:]              \n",
    "\n",
    "\n",
    "tokenized_len_dataset = tokenized_dataset_len(train_dataset, tokenizer)\n",
    "\n",
    "print('최대 길이 : ', max(len(i) for i in tokenized_len_dataset))\n",
    "print('평균 길이 : ', sum(map(len, tokenized_len_dataset))/len(tokenized_len_dataset))\n",
    "plt.hist([len(s) for s in tokenized_len_dataset], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df5b5510-0cc8-450d-90b0-2732a24a3f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f95900ad76e54fb8b6bc2e1f152e48ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79598b626b834bf88ed1bbeda81c35cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 16:27:47 - INFO - __main__ -   ***** Running training *****\n",
      "04/21/2021 16:27:47 - INFO - __main__ -     Num examples = 9000\n",
      "04/21/2021 16:27:47 - INFO - __main__ -     Num Epochs = 10\n",
      "04/21/2021 16:27:47 - INFO - __main__ -     Total train batch size = 16\n",
      "04/21/2021 16:27:47 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
      "04/21/2021 16:27:47 - INFO - __main__ -     Total optimization steps = 5630\n",
      "04/21/2021 16:27:47 - INFO - __main__ -     Logging steps = 562\n",
      "04/21/2021 16:27:47 - INFO - __main__ -     Save steps = 562\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e7c9ff3a734846a1b0f01189a56d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=10.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d09eb5a9414c4191833220aa57d44d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=563.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "04/21/2021 16:38:39 - INFO - __main__ -     global steps = 562\n",
      "04/21/2021 16:38:39 - INFO - __main__ -   ***** Running evaluation on train dataset *****\n",
      "04/21/2021 16:38:39 - INFO - __main__ -     Num examples = 9000\n",
      "04/21/2021 16:38:39 - INFO - __main__ -     Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c1f0d1cfd5f42c5bca46434f0670f99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=563.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 16:42:03 - INFO - __main__ -   ***** Eval results *****\n",
      "04/21/2021 16:42:03 - INFO - __main__ -     acc = 0.7360\n",
      "04/21/2021 16:42:03 - INFO - __main__ -     loss = 0.7380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 16:42:58 - INFO - __main__ -   Saving model checkpoint to ./model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f61f3e3ff448fca4ee87d83cd3e3cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=563.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 16:53:50 - INFO - __main__ -     global steps = 1124\n",
      "04/21/2021 16:53:50 - INFO - __main__ -   ***** Running evaluation on train dataset *****\n",
      "04/21/2021 16:53:50 - INFO - __main__ -     Num examples = 9000\n",
      "04/21/2021 16:53:50 - INFO - __main__ -     Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0009b38b4fa140f4a51f07228fadf271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=563.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 16:57:13 - INFO - __main__ -   ***** Eval results *****\n",
      "04/21/2021 16:57:13 - INFO - __main__ -     acc = 0.8093\n",
      "04/21/2021 16:57:13 - INFO - __main__ -     loss = 0.4932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 16:58:09 - INFO - __main__ -   Saving model checkpoint to ./model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0102f327d89437db61915b37f00bb21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=563.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 17:09:00 - INFO - __main__ -     global steps = 1686\n",
      "04/21/2021 17:09:00 - INFO - __main__ -   ***** Running evaluation on train dataset *****\n",
      "04/21/2021 17:09:00 - INFO - __main__ -     Num examples = 9000\n",
      "04/21/2021 17:09:00 - INFO - __main__ -     Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcaaa7a1e6834d3188964dd525c49932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=563.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 17:12:23 - INFO - __main__ -   ***** Eval results *****\n",
      "04/21/2021 17:12:23 - INFO - __main__ -     acc = 0.8628\n",
      "04/21/2021 17:12:23 - INFO - __main__ -   ***** Running evaluation on test dataset *****\n",
      "04/21/2021 17:12:23 - INFO - __main__ -     Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49cf809c1fed47a393cfb72402931de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Predicting', max=63.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 17:12:46 - INFO - __main__ -     loss = 0.3363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 17:13:24 - INFO - __main__ -   Saving model checkpoint to ./model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0c043910a74259811f5ff9691422c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=563.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 17:24:14 - INFO - __main__ -     global steps = 2248\n",
      "04/21/2021 17:24:14 - INFO - __main__ -   ***** Running evaluation on train dataset *****\n",
      "04/21/2021 17:24:14 - INFO - __main__ -     Num examples = 9000\n",
      "04/21/2021 17:24:14 - INFO - __main__ -     Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a31e3d56c014b0fbf9e9cd0219f797c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=563.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 17:27:38 - INFO - __main__ -   ***** Eval results *****\n",
      "04/21/2021 17:27:38 - INFO - __main__ -     acc = 0.9211\n",
      "04/21/2021 17:27:38 - INFO - __main__ -   ***** Running evaluation on test dataset *****\n",
      "04/21/2021 17:27:38 - INFO - __main__ -     Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c25b2bcb3f45fc80b8dc276f1c9f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Predicting', max=63.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 17:28:01 - INFO - __main__ -     loss = 0.2028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 17:28:38 - INFO - __main__ -   Saving model checkpoint to ./model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce7c748ece54de689174c5f8fc006c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=563.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 17:39:29 - INFO - __main__ -     global steps = 2810\n",
      "04/21/2021 17:39:29 - INFO - __main__ -   ***** Running evaluation on train dataset *****\n",
      "04/21/2021 17:39:29 - INFO - __main__ -     Num examples = 9000\n",
      "04/21/2021 17:39:29 - INFO - __main__ -     Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18bbed6877554c3a8b33dd8b4bd31b98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=563.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 17:42:54 - INFO - __main__ -   ***** Eval results *****\n",
      "04/21/2021 17:42:54 - INFO - __main__ -     acc = 0.9547\n",
      "04/21/2021 17:42:54 - INFO - __main__ -   ***** Running evaluation on test dataset *****\n",
      "04/21/2021 17:42:54 - INFO - __main__ -     Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66bd124b6bc5488186c67f6dda62e71e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Predicting', max=63.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 17:43:16 - INFO - __main__ -     loss = 0.1226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 17:43:54 - INFO - __main__ -   Saving model checkpoint to ./model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e50cff2153cf4ae4827a5e2afbd814e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=563.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 17:54:46 - INFO - __main__ -     global steps = 3372\n",
      "04/21/2021 17:54:46 - INFO - __main__ -   ***** Running evaluation on train dataset *****\n",
      "04/21/2021 17:54:46 - INFO - __main__ -     Num examples = 9000\n",
      "04/21/2021 17:54:46 - INFO - __main__ -     Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b9dfd4430894c1db6a7cdb674cf62e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=563.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 17:58:10 - INFO - __main__ -   ***** Eval results *****\n",
      "04/21/2021 17:58:10 - INFO - __main__ -     acc = 0.9704\n",
      "04/21/2021 17:58:10 - INFO - __main__ -   ***** Running evaluation on test dataset *****\n",
      "04/21/2021 17:58:10 - INFO - __main__ -     Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f4d029617a47e5be7b04d579745026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Predicting', max=63.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 17:58:32 - INFO - __main__ -     loss = 0.0781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 17:59:10 - INFO - __main__ -   Saving model checkpoint to ./model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6a28c538e54eadbdd89feba6761ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=563.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 18:10:02 - INFO - __main__ -     global steps = 3934\n",
      "04/21/2021 18:10:02 - INFO - __main__ -   ***** Running evaluation on train dataset *****\n",
      "04/21/2021 18:10:02 - INFO - __main__ -     Num examples = 9000\n",
      "04/21/2021 18:10:02 - INFO - __main__ -     Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c6aa33dc554cde92b7a86bfef61186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=563.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 18:13:26 - INFO - __main__ -   ***** Eval results *****\n",
      "04/21/2021 18:13:26 - INFO - __main__ -     acc = 0.9808\n",
      "04/21/2021 18:13:26 - INFO - __main__ -   ***** Running evaluation on test dataset *****\n",
      "04/21/2021 18:13:26 - INFO - __main__ -     Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "034b88359a50474abf42e49c878fc6cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Predicting', max=63.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 18:13:48 - INFO - __main__ -     loss = 0.0505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 18:14:26 - INFO - __main__ -   Saving model checkpoint to ./model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f85134f220c341459c77fb7e04e1b8f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=563.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 18:25:16 - INFO - __main__ -     global steps = 4496\n",
      "04/21/2021 18:25:16 - INFO - __main__ -   ***** Running evaluation on train dataset *****\n",
      "04/21/2021 18:25:16 - INFO - __main__ -     Num examples = 9000\n",
      "04/21/2021 18:25:16 - INFO - __main__ -     Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0842df8c1fb04a0a8cd6fbb20efc7967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=563.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 18:28:40 - INFO - __main__ -   ***** Eval results *****\n",
      "04/21/2021 18:28:40 - INFO - __main__ -     acc = 0.9882\n",
      "04/21/2021 18:28:40 - INFO - __main__ -   ***** Running evaluation on test dataset *****\n",
      "04/21/2021 18:28:40 - INFO - __main__ -     Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2cd90bd187f497498ba5b097feb40e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Predicting', max=63.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 18:29:02 - INFO - __main__ -     loss = 0.0301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 18:29:40 - INFO - __main__ -   Saving model checkpoint to ./model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb6571d7b6543649001f409d2bff2bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=563.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 18:40:29 - INFO - __main__ -     global steps = 5058\n",
      "04/21/2021 18:40:29 - INFO - __main__ -   ***** Running evaluation on train dataset *****\n",
      "04/21/2021 18:40:29 - INFO - __main__ -     Num examples = 9000\n",
      "04/21/2021 18:40:29 - INFO - __main__ -     Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c350f68eba0747d59ba8ad6e9e3224fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=563.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 18:43:52 - INFO - __main__ -   ***** Eval results *****\n",
      "04/21/2021 18:43:53 - INFO - __main__ -     acc = 0.9931\n",
      "04/21/2021 18:43:53 - INFO - __main__ -   ***** Running evaluation on test dataset *****\n",
      "04/21/2021 18:43:53 - INFO - __main__ -     Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d940f48aa7bb4e809faebdc2b04a8294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Predicting', max=63.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 18:44:15 - INFO - __main__ -     loss = 0.0188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 18:44:53 - INFO - __main__ -   Saving model checkpoint to ./model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "585dd7e04d8044a8861ba84fec04a680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=563.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 18:55:42 - INFO - __main__ -     global steps = 5620\n",
      "04/21/2021 18:55:42 - INFO - __main__ -   ***** Running evaluation on train dataset *****\n",
      "04/21/2021 18:55:42 - INFO - __main__ -     Num examples = 9000\n",
      "04/21/2021 18:55:42 - INFO - __main__ -     Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784084f9c8534eb5853337e0c5c6e94e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=563.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 18:59:05 - INFO - __main__ -   ***** Eval results *****\n",
      "04/21/2021 18:59:05 - INFO - __main__ -     acc = 0.9949\n",
      "04/21/2021 18:59:05 - INFO - __main__ -   ***** Running evaluation on test dataset *****\n",
      "04/21/2021 18:59:05 - INFO - __main__ -     Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb11fac5b478469b887a39321650973e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Predicting', max=63.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 18:59:28 - INFO - __main__ -     loss = 0.0132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 19:00:05 - INFO - __main__ -   Saving model checkpoint to ./model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "init_logger()\n",
    "#train_dataset = load_data(\"/opt/ml/input/data/train/train+all.tsv\")\n",
    "train_dataset = load_data(\"/opt/ml/input/data/train/train.tsv\")\n",
    "\n",
    "test_dataset = load_data(\"/opt/ml/input/data/test/test.tsv\")\n",
    "#dev_dataset = load_data(\"./dataset/train/dev.tsv\")\n",
    "#train_label = train_dataset['label'].values\n",
    "#train_dataset.columns= ['link','sentence' 'entity_01','e1s','e1e','entity_02','e2s','e2e','label']\n",
    "ADDITIONAL_SPECIAL_TOKENS = [\"<e1>\", \"</e1>\", \"<e2>\", \"</e2>\"]\n",
    "MODEL_NAME = \"xlm-roberta-large\"\n",
    "#MODEL_NAME = \"xlm-roXLMRobertaa-large\"\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\": ADDITIONAL_SPECIAL_TOKENS})\n",
    "\n",
    "#     li = [len(i) for i in tokenized_len_dataset]\n",
    "#     train_dataset['len'] = li\n",
    "\n",
    "#     train_dataset = train_dataset[train_dataset['len'] <= 250]\n",
    "#     train_dataset = train_dataset.reset_index(drop=False, inplace=False)\n",
    "#     del train_dataset['index']\n",
    "\n",
    "\n",
    "train_Dataset = convert_sentence_to_features(train_dataset, tokenizer, max_len = 345+2)\n",
    "test_Dataset = convert_sentence_to_features(test_dataset, tokenizer, max_len=345+2)\n",
    "with open('/opt/ml/input/data/label_type.pkl', 'rb') as f:\n",
    "    label_type = pickle.load(f)\n",
    "\n",
    "trainer = Trainer(eval_batch_size=16,train_batch_size=16, num_labels = 42,\n",
    "                  max_steps=-1, weight_decay=0.0, learning_rate= 2e-5, \n",
    "                  adam_epsilon=1e-8, warmup_steps=0, num_train_epochs=10,\n",
    "                  logging_steps=562, save_steps=562, max_grad_norm=1.0, \n",
    "                  model_dir='./model', gradient_accumulation_steps=1,dropout_rate = 0.1, classifier_epoch=3,\n",
    "                  label_dict=label_type,Model_name=MODEL_NAME,train_dataset=train_Dataset,\n",
    "                  test_dataset=test_Dataset)\n",
    "\n",
    "do_train = True\n",
    "do_test = False\n",
    "if do_train:\n",
    "    trainer.train()\n",
    "    #trainer.classifier_train()\n",
    "\n",
    "if do_test:\n",
    "    trainer.test_pred()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d4e429-7676-46bd-bd6f-501782383863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a04a382-c41f-4e00-a047-cd128cc06f64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
