{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b741768a-d449-42f0-9290-da4f8964d7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import AutoTokenizer, XLMRobertaConfig, XLMRobertaTokenizer\n",
    "from transformers import XLMRobertaModel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from itertools import chain\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "import copy\n",
    "import csv\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import logging\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff82ea82-155f-4806-8da9-f101908fc89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed=42\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cdfb42c-1453-4e3c-895a-d182caddd437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 구성.\n",
    "class RE_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenized_dataset):\n",
    "        self.tokenized_dataset = tokenized_dataset\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_dataset.items()}\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_dataset['label'])\n",
    "\n",
    "# 처음 불러온 tsv 파일을 원하는 형태의 DataFrame으로 변경 시켜줍니다.\n",
    "# 변경한 DataFrame 형태는 baseline code description 이미지를 참고해주세요.\n",
    "def preprocessing_dataset(dataset):\n",
    "    out_dataset = pd.DataFrame({'sentence':list(dataset['sentence']),'entity_01':list(dataset['entity_01']), 'entity_02':list(dataset['entity_02']),'label':list(dataset['label'])})\n",
    "    return out_dataset\n",
    "\n",
    "# tsv 파일을 불러옵니다.\n",
    "def load_data(dataset_dir):\n",
    "  # load label_type, classes\n",
    "#     with open('/opt/ml/input/data/label_type.pkl', 'rb') as f:\n",
    "#         label_type = pickle.load(f)\n",
    "  # load dataset\n",
    "    dataset = pd.read_csv(dataset_dir, delimiter='\\t')\n",
    "  # preprecessing dataset\n",
    "    dataset = preprocessing_dataset(dataset)\n",
    "  \n",
    "    return dataset\n",
    "\n",
    "# XLMRoberta input을 위한 tokenizing.\n",
    "# tip! 다양한 종류의 tokenizer와 special token들을 활용하는 것으로도 새로운 시도를 해볼 수 있습니다.\n",
    "# baseline code에서는 2가지 부분을 활용했습니다.\n",
    "# def append_token(dataset, tokenizer):\n",
    "#     for (ex_index, example) in enumerate(dataset):\n",
    "        \n",
    "    \n",
    "\n",
    "# def tokenized_dataset(dataset, tokenizer):\n",
    "#     concat_entity = []\n",
    "#     for e01, e02 in zip(dataset['entity_01'], dataset['entity_02']):\n",
    "#         temp = ''\n",
    "#         temp = e01 + '[SEP]' + e02\n",
    "#         concat_entity.append(temp)\n",
    "#         tokenized_sentences = tokenizer(\n",
    "#       #concat_entity,\n",
    "#           list(dataset['sentence']),\n",
    "#           return_tensors=\"pt\",\n",
    "#           padding=True,\n",
    "#           truncation=True,\n",
    "#           max_length=150,\n",
    "#           add_special_tokens=True,\n",
    "#           )\n",
    "#     return tokenized_sentences\n",
    "\n",
    "def tokenized_dataset_len(dataset, tokenizer):\n",
    "    li = []\n",
    "    for sentence in dataset['sentence']:\n",
    "        li.append(tokenizer.tokenize(sentence))\n",
    "    return li\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6855113d-1ebe-4e5c-ba30-a10b5ef8b812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(preds, labels):\n",
    "    assert len(preds) == len(labels)\n",
    "    return acc_and_f1(preds, labels)\n",
    "\n",
    "\n",
    "def simple_accuracy(preds, labels):\n",
    "    return (preds == labels).mean()\n",
    "\n",
    "\n",
    "def official_f1():\n",
    "\n",
    "    with open(os.path.join('/opt/ml/eval/result.txt'), \"r\", encoding=\"utf-8\") as f:\n",
    "        macro_result = list(f)[-1]\n",
    "        macro_result = macro_result.split(\":\")[1].replace(\">>>\", \"\").strip()\n",
    "        macro_result = macro_result.split(\"=\")[1].strip().replace(\"%\", \"\")\n",
    "        macro_result = float(macro_result) / 100\n",
    "\n",
    "    return macro_result\n",
    "\n",
    "def acc_and_f1(preds, labels, average=\"macro\"):\n",
    "    acc = simple_accuracy(preds, labels)\n",
    "    return {\n",
    "        \"acc\": acc,\n",
    "        #\"f1\": official_f1(),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cff171a4-ad81-46e4-abe9-b019a4ef9c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sentence_to_features(train_dataset, tokenizer, max_len):\n",
    "    \n",
    "    max_seq_len=max_len\n",
    "    cls_token=tokenizer.cls_token\n",
    "    #cls_token_segment_id=tokenizer.cls_token_id\n",
    "    cls_token_segment_id=0\n",
    "    sep_token=tokenizer.sep_token\n",
    "    pad_token=1\n",
    "    pad_token_segment_id=0\n",
    "    sequence_a_segment_id=0\n",
    "    add_sep_token=False\n",
    "    mask_padding_with_zero=True\n",
    "    \n",
    "    all_input_ids = []\n",
    "    all_attention_mask = []\n",
    "    all_token_type_ids = []\n",
    "    all_e1_mask=[]\n",
    "    all_e2_mask=[]\n",
    "    all_label=[]\n",
    "    for idx in tqdm(range(len(train_dataset)), desc='tokenizing'):\n",
    "#         if train_dataset['e1s'][idx] > train_dataset['e2s'][idx]:\n",
    "#             train_dataset['sentence'][idx] = train_dataset['sentence'][idx][:train_dataset['e2s'][idx]] + ' <e2> ' + train_dataset['sentence'][idx][train_dataset['e2s'][idx]:train_dataset['e2e'][idx]+1] + ' </e2> ' + train_dataset['sentence'][idx][train_dataset['e2e'][idx]+1:train_dataset['e1s'][idx]] + ' <e1> ' + train_dataset['sentence'][idx][train_dataset['e1s'][idx]:train_dataset['e1e'][idx]+1] + ' </e1> ' + train_dataset['sentence'][idx][train_dataset['e1e'][idx]+1:]\n",
    "#         else:\n",
    "#             train_dataset['sentence'][idx] = train_dataset['sentence'][idx][:train_dataset['e1s'][idx]] + ' <e1> ' + train_dataset['sentence'][idx][train_dataset['e1s'][idx]:train_dataset['e1e'][idx]+1] + ' </e1> ' + train_dataset['sentence'][idx][train_dataset['e1e'][idx]+1:train_dataset['e2s'][idx]] + ' <e2> ' + train_dataset['sentence'][idx][train_dataset['e2s'][idx]:train_dataset['e2e'][idx]+1] + ' </e2> ' + train_dataset['sentence'][idx][train_dataset['e2e'][idx]+1:]    \n",
    "        token = tokenizer.tokenize(train_dataset['sentence'][idx])\n",
    "        \n",
    "#         e11_p = token.index(\"<e1>\")  # the start position of entity1\n",
    "#         e12_p = token.index(\"</e1>\")  # the end position of entity1\n",
    "#         e21_p = token.index(\"<e2>\")  # the start position of entity2\n",
    "#         e22_p = token.index(\"</e2>\")  # the end position of entity2\n",
    "\n",
    "        e1_p = np.where(np.isin(token, '#'))\n",
    "        e2_p = np.where(np.isin(token, '@'))\n",
    "\n",
    "        e11_p = e1_p[0][0]  # the start position of entity1\n",
    "        e12_p = e1_p[0][1]  # the end position of entity1\n",
    "        e21_p = e2_p[0][0] # the start position of entity2\n",
    "        e22_p = e2_p[0][1]  # the end position of entity2\n",
    "\n",
    "        \n",
    "#         token[e11_p] = \"$\"\n",
    "#         token[e12_p] = \"$\"\n",
    "#         token[e21_p] = \"#\"\n",
    "#         token[e22_p] = \"#\"\n",
    "\n",
    "        #print(token)\n",
    "\n",
    "        e11_p += 1\n",
    "        e12_p += 1\n",
    "        e21_p += 1\n",
    "        e22_p += 1\n",
    "\n",
    "\n",
    "        if len(token) < max_seq_len + 1 :\n",
    "#            token = token[: (max_seq_len - special_tokens_count)]\n",
    "\n",
    "#         if add_sep_token:\n",
    "#             token += [sep_token]\n",
    "\n",
    "            token_type_ids = [sequence_a_segment_id] * len(token)\n",
    "\n",
    "            token = [cls_token] + token \n",
    "            token_type_ids = [cls_token_segment_id] + token_type_ids\n",
    "\n",
    "            input_ids = tokenizer.convert_tokens_to_ids(token)\n",
    "\n",
    "            attention_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
    "\n",
    "            padding_length = max_seq_len - len(input_ids)\n",
    "            input_ids = input_ids + ([pad_token] * padding_length)\n",
    "            attention_mask = attention_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\n",
    "            token_type_ids = token_type_ids + ([pad_token_segment_id] * padding_length)\n",
    "\n",
    "            e1_mask = [0] * len(attention_mask)\n",
    "            e2_mask = [0] * len(attention_mask)\n",
    "\n",
    "            for i in range(e11_p, e12_p + 1):\n",
    "                e1_mask[i] = 1\n",
    "            for i in range(e21_p, e22_p + 1):\n",
    "                e2_mask[i] = 1\n",
    "\n",
    "            assert len(input_ids) == max_seq_len, \"Error with input length {} vs {}\".format(len(input_ids), max_seq_len)\n",
    "            assert len(attention_mask) == max_seq_len, \"Error with attention mask length {} vs {}\".format(\n",
    "                len(attention_mask), max_seq_len\n",
    "            )\n",
    "            assert len(token_type_ids) == max_seq_len, \"Error with token type length {} vs {}\".format(\n",
    "                len(token_type_ids), max_seq_len\n",
    "            )\n",
    "\n",
    "            all_input_ids.append(input_ids)\n",
    "            all_attention_mask.append(attention_mask)\n",
    "            all_token_type_ids.append(token_type_ids)\n",
    "            all_e1_mask.append(e1_mask)\n",
    "            all_e2_mask.append(e2_mask)\n",
    "            all_label.append(train_dataset['label'][idx])\n",
    "    \n",
    "    all_features = {\n",
    "        'input_ids' : torch.tensor(all_input_ids),\n",
    "        'attention_mask' : torch.tensor(all_attention_mask),\n",
    "        'token_type_ids' : torch.tensor(all_token_type_ids),\n",
    "        'e1_mask' : torch.tensor(all_e1_mask),\n",
    "        'e2_mask' : torch.tensor(all_e2_mask),\n",
    "        'label' : torch.tensor(all_label)\n",
    "    }  \n",
    "    return RE_Dataset(all_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5fa4e5-1761-4845-b030-6f70f2f01db2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6fa607d-195f-428d-a722-c6e6c1bd8aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_loss(loss, reduction='mean'):\n",
    "    return loss.mean() if reduction=='mean' else loss.sum() if reduction=='sum' else loss\n",
    "\n",
    "# Implementation from fastai https://github.com/fastai/fastai2/blob/master/fastai2/layers.py#L338\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, e:float=0.05, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.e,self.reduction = e,reduction\n",
    "    \n",
    "    def forward(self, output, target):\n",
    "        # number of classes\n",
    "        c = output.size()[-1]\n",
    "        log_preds = F.log_softmax(output, dim=-1)\n",
    "        loss = reduce_loss(-log_preds.sum(dim=-1), self.reduction)\n",
    "        nll = F.nll_loss(log_preds, target, reduction=self.reduction)\n",
    "        # (1-ε)* H(q,p) + ε*H(u,p)\n",
    "        return (1-self.e)*nll + self.e*(loss/c) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a25068cb-7a20-49fc-8972-7e18830dd6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_rate=0.0, use_activation=True):\n",
    "        super(FCLayer, self).__init__()\n",
    "        self.use_activation = use_activation\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        if self.use_activation:\n",
    "            x = self.tanh(x)\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "class RXLMRoberta(XLMRobertaModel):\n",
    "    def __init__(self,  model_name, config, dropout_rate):\n",
    "        super(RXLMRoberta, self).__init__(config)\n",
    "        self.XLMRoberta = XLMRobertaModel.from_pretrained(model_name, config=config)  # Load pretrained XLMRoberta\n",
    "\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.cls_fc_layer = FCLayer(config.hidden_size, config.hidden_size, dropout_rate)\n",
    "        self.entity_fc_layer1 = FCLayer(config.hidden_size, config.hidden_size, dropout_rate)\n",
    "        self.entity_fc_layer2 = FCLayer(config.hidden_size, config.hidden_size, dropout_rate)\n",
    "\n",
    "        self.label_classifier = FCLayer(\n",
    "            config.hidden_size * 3,\n",
    "            config.num_labels,\n",
    "            dropout_rate,\n",
    "            use_activation=False,\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def entity_average(hidden_output, e_mask):\n",
    "        \"\"\"\n",
    "        Average the entity hidden state vectors (H_i ~ H_j)\n",
    "        :param hidden_output: [batch_size, j-i+1, dim]\n",
    "        :param e_mask: [batch_size, max_seq_len]\n",
    "                e.g. e_mask[0] == [0, 0, 0, 1, 1, 1, 0, 0, ... 0]\n",
    "        :return: [batch_size, dim]\n",
    "        \"\"\"\n",
    "        e_mask_unsqueeze = e_mask.unsqueeze(1)  # [b, 1, j-i+1]\n",
    "        length_tensor = (e_mask != 0).sum(dim=1).unsqueeze(1)  # [batch_size, 1]\n",
    "\n",
    "        # [b, 1, j-i+1] * [b, j-i+1, dim] = [b, 1, dim] -> [b, dim]\n",
    "        sum_vector = torch.bmm(e_mask_unsqueeze.float(), hidden_output).squeeze(1)\n",
    "        avg_vector = sum_vector.float() / length_tensor.float()  # broadcasting\n",
    "        return avg_vector\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, labels, e1_mask, e2_mask):\n",
    "        outputs = self.XLMRoberta(\n",
    "            input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids\n",
    "        )  # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "        sequence_output = outputs[0]\n",
    "        pooled_output = outputs[1]  # [CLS]\n",
    "    \n",
    "        e1_h = self.entity_average(sequence_output, e1_mask)\n",
    "        e2_h = self.entity_average(sequence_output, e2_mask)\n",
    "        # Dropout -> tanh -> fc_layer (Share FC layer for e1 and e2)\n",
    "        pooled_output = self.cls_fc_layer(pooled_output)\n",
    "        e1_h = self.entity_fc_layer1(e1_h)\n",
    "        e2_h = self.entity_fc_layer2(e2_h)\n",
    "        # Concat -> fc_layer\n",
    "        #concat_h = torch.cat([pooled_output, e1_h, e2_h, torch.abs(torch.sub(e1_h,e2_h))], dim=-1)\n",
    "        concat_h = torch.cat([pooled_output, e1_h, e2_h], dim=-1)\n",
    "        logits = self.label_classifier(concat_h)\n",
    "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
    "        # Softmax\n",
    "        if labels is not None:\n",
    "            if self.num_labels == 1:\n",
    "                loss_fct = nn.MSELoss()\n",
    "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "            else:\n",
    "                loss_fct = nn.CrossEntropyLoss()\n",
    "                #loss_fct = LabelSmoothingCrossEntropy()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "            outputs = (loss,) + outputs\n",
    "\n",
    "        return outputs  # (loss), logits, (hidden_states), (attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0765d127-ca15-47ef-a8d1-df6fd1530e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14e99d0c-e953-41a0-a38e-87c51f6ba795",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "class Trainer(object):\n",
    "    def __init__(self,num_labels, label_dict,logging_steps, save_steps,max_steps,\n",
    "                 num_train_epochs,warmup_steps,adam_epsilon,learning_rate,gradient_accumulation_steps,\n",
    "                 max_grad_norm, eval_batch_size, train_batch_size, model_dir, dropout_rate,\n",
    "                 weight_decay, Model_name ,train_dataset=None, dev_dataset=None, test_dataset=None):\n",
    "        #self.args = args\n",
    "        self.train_dataset = train_dataset\n",
    "        self.eval_batch_size = eval_batch_size\n",
    "        self.train_batch_size = train_batch_size\n",
    "        self.dev_dataset = dev_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "        self.Model_name = Model_name\n",
    "        self.label_lst = label_dict\n",
    "        self.num_labels = num_labels\n",
    "        self.max_steps = max_steps\n",
    "        self.weight_decay = weight_decay\n",
    "        self.learning_rate = learning_rate\n",
    "        self.adam_epsilon=adam_epsilon\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.num_train_epochs = num_train_epochs\n",
    "        self.logging_steps = logging_steps\n",
    "        self.save_steps = save_steps\n",
    "        self.max_grad_norm = max_grad_norm\n",
    "        self.model_dir = model_dir\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.gradient_accumulation_steps = gradient_accumulation_steps\n",
    "        self.config = XLMRobertaConfig.from_pretrained(\n",
    "            self.Model_name,\n",
    "            num_labels=self.num_labels,\n",
    "            #id2label={str(i): label for i, label in enumerate(self.label_lst)},\n",
    "            id2label=self.label_lst,\n",
    "            #label2id={label: i for key, label in self.label_lst},\n",
    "            label2id={value : key for key, value in self.label_lst.items()}\n",
    "        )\n",
    "        self.model = RXLMRoberta(\n",
    "            self.Model_name, config=self.config, dropout_rate = self.dropout_rate,\n",
    "        )\n",
    "\n",
    "        # GPU or CPU\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def train(self):\n",
    "        train_sampler = RandomSampler(self.train_dataset)\n",
    "        train_dataloader = DataLoader(\n",
    "            self.train_dataset,\n",
    "            sampler=train_sampler,\n",
    "            batch_size=self.train_batch_size,\n",
    "        )\n",
    "\n",
    "        if self.max_steps > 0:\n",
    "            t_total = self.max_steps\n",
    "            self.num_train_epochs = (\n",
    "                self.max_steps // (len(train_dataloader) // self.gradient_accumulation_steps) + 1\n",
    "            )\n",
    "        else:\n",
    "            t_total = len(train_dataloader) // self.gradient_accumulation_steps * self.num_train_epochs\n",
    "\n",
    "        # Prepare optimizer and schedule (linear warmup and decay)\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in self.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": self.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = AdamW(\n",
    "            optimizer_grouped_parameters,\n",
    "            lr=self.learning_rate,\n",
    "            eps=self.adam_epsilon,\n",
    "        )\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=self.warmup_steps,\n",
    "            num_training_steps=t_total,\n",
    "        )\n",
    "        \n",
    "        #scaler = torch.cuda.amp.GradScaler()\n",
    "        # Train!\n",
    "        logger.info(\"***** Running training *****\")\n",
    "        logger.info(\"  Num examples = %d\", len(self.train_dataset))\n",
    "        logger.info(\"  Num Epochs = %d\", self.num_train_epochs)\n",
    "        logger.info(\"  Total train batch size = %d\", self.train_batch_size)\n",
    "        logger.info(\"  Gradient Accumulation steps = %d\", self.gradient_accumulation_steps)\n",
    "        logger.info(\"  Total optimization steps = %d\", t_total)\n",
    "        logger.info(\"  Logging steps = %d\", self.logging_steps)\n",
    "        logger.info(\"  Save steps = %d\", self.save_steps)\n",
    "\n",
    "        global_step = 0\n",
    "        tr_loss = 0.0\n",
    "        self.model.zero_grad()\n",
    "\n",
    "        train_iterator = tqdm(range(int(self.num_train_epochs)), desc=\"Epoch\")\n",
    "\n",
    "        for _ in train_iterator:\n",
    "            epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\")\n",
    "            for step, batch in enumerate(epoch_iterator):\n",
    "                self.model.train()\n",
    "                batch = tuple(batch[t].to(self.device) for t in batch)  # GPU or CPU\n",
    "                inputs = {\n",
    "                    \"input_ids\": batch[0],\n",
    "                    \"attention_mask\": batch[1],\n",
    "                    \"token_type_ids\" : batch[2],\n",
    "                    \"labels\": batch[5],\n",
    "                    \"e1_mask\": batch[3],\n",
    "                    \"e2_mask\": batch[4]\n",
    "                }\n",
    "                #with torch.cuda.amp.autocast():\n",
    "                outputs = self.model(**inputs)\n",
    "                loss = outputs[0]\n",
    "\n",
    "                if self.gradient_accumulation_steps > 1:\n",
    "                    loss = loss / self.gradient_accumulation_steps\n",
    "\n",
    "                #scaler.scale(loss).backward()\n",
    "                loss.backward()\n",
    "\n",
    "                tr_loss += loss.item()\n",
    "                if (step + 1) % self.gradient_accumulation_steps == 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)\n",
    "\n",
    "                    optimizer.step()\n",
    "                    #scaler.step(optimizer)\n",
    "                    #scaler.update()\n",
    "                    scheduler.step()  # Update learning rate schedule\n",
    "                    self.model.zero_grad()\n",
    "                    global_step += 1\n",
    "\n",
    "                    if self.logging_steps > 0 and global_step % self.logging_steps == 0:\n",
    "                        logger.info(\"  global steps = %d\", global_step)\n",
    "                        self.evaluate(\"train\")  # There is no dev set for semeval task\n",
    "\n",
    "                    if self.save_steps > 0 and global_step % self.save_steps == 0:\n",
    "                        self.save_model()\n",
    "\n",
    "                if 0 < self.max_steps < global_step:\n",
    "                    epoch_iterator.close()\n",
    "                    break\n",
    "\n",
    "            if 0 < self.max_steps < global_step:\n",
    "                train_iterator.close()\n",
    "                break\n",
    "\n",
    "        return global_step, tr_loss / global_step\n",
    "\n",
    "    def evaluate(self, mode):\n",
    "        # We use test dataset because semeval doesn't have dev dataset\n",
    "        if mode == \"test\":\n",
    "            dataset = self.test_dataset\n",
    "        elif mode == \"dev\":\n",
    "            dataset = self.dev_dataset\n",
    "        elif mode == \"train\":\n",
    "            dataset = self.train_dataset\n",
    "        else:\n",
    "            raise Exception(\"Only dev and test dataset available\")\n",
    "\n",
    "        eval_sampler = SequentialSampler(dataset)\n",
    "        eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=self.eval_batch_size)\n",
    "\n",
    "        # Eval!\n",
    "        logger.info(\"***** Running evaluation on %s dataset *****\", mode)\n",
    "        logger.info(\"  Num examples = %d\", len(dataset))\n",
    "        logger.info(\"  Batch size = %d\", self.eval_batch_size)\n",
    "        eval_loss = 0.0\n",
    "        nb_eval_steps = 0\n",
    "        preds = None\n",
    "        out_label_ids = None\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "            batch = tuple(batch[t].to(self.device) for t in batch)\n",
    "            with torch.no_grad():\n",
    "                inputs = {\n",
    "                    \"input_ids\": batch[0],\n",
    "                    \"attention_mask\": batch[1],\n",
    "                    \"token_type_ids\": batch[2],\n",
    "                    \"labels\": batch[5],\n",
    "                    \"e1_mask\": batch[3],\n",
    "                    \"e2_mask\": batch[4],\n",
    "                }\n",
    "                #with torch.cuda.amp.autocast():\n",
    "                outputs = self.model(**inputs)\n",
    "                tmp_eval_loss, logits = outputs[:2]\n",
    "                eval_loss += tmp_eval_loss.mean().item()\n",
    "            nb_eval_steps += 1\n",
    "\n",
    "            if preds is None:\n",
    "                preds = logits.detach().cpu().numpy()\n",
    "                out_label_ids = inputs[\"labels\"].detach().cpu().numpy()\n",
    "            else:\n",
    "                preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "                out_label_ids = np.append(out_label_ids, inputs[\"labels\"].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "        eval_loss = eval_loss / nb_eval_steps\n",
    "        results = {\"loss\": eval_loss}\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "\n",
    "        result = compute_metrics(preds, out_label_ids)\n",
    "        results.update(result)\n",
    "\n",
    "        logger.info(\"***** Eval results *****\")\n",
    "        for key in sorted(results.keys()):\n",
    "            logger.info(\"  {} = {:.4f}\".format(key, results[key]))\n",
    "\n",
    "        return results\n",
    "    \n",
    "    def test_pred(self):\n",
    "        test_dataset = self.test_dataset\n",
    "        test_sampler = SequentialSampler(test_dataset)\n",
    "        test_dataloader = DataLoader(test_dataset, sampler=test_sampler,batch_size=self.eval_batch_size)\n",
    "\n",
    "        # Eval!\n",
    "        logger.info(\"***** Running evaluation on %s dataset *****\", \"test\")\n",
    "        #logger.info(\"  Num examples = %d\", len(dataset))\n",
    "        logger.info(\"  Batch size = %d\", self.eval_batch_size)\n",
    "\n",
    "        nb_eval_steps = 0\n",
    "        preds = None\n",
    "        out_label_ids = None\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        for batch in tqdm(test_dataloader, desc=\"Predicting\"):\n",
    "            batch = tuple(batch[t].to(self.device) for t in batch)\n",
    "            with torch.no_grad():\n",
    "                inputs = {\n",
    "                    \"input_ids\": batch[0],\n",
    "                    \"attention_mask\": batch[1],\n",
    "                    \"token_type_ids\": batch[2],\n",
    "                    \"labels\": None,\n",
    "                    \"e1_mask\": batch[3],\n",
    "                    \"e2_mask\": batch[4],\n",
    "                }\n",
    "                outputs = self.model(**inputs)\n",
    "                #print(outputs)\n",
    "                pred = outputs[0]\n",
    "\n",
    "            nb_eval_steps += 1\n",
    "\n",
    "            if preds is None:\n",
    "                preds = pred.detach().cpu().numpy()\n",
    "                #out_label_ids = inputs[\"labels\"].detach().cpu().numpy()\n",
    "            else:\n",
    "                preds = np.append(preds, pred.detach().cpu().numpy(), axis=0)\n",
    "                #out_label_ids = np.append(out_label_ids, inputs[\"labels\"].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "        df = pd.DataFrame(preds, columns=['pred'])\n",
    "        df.to_csv('RXLMRoberta_layersplit_nerdata_epoch7.csv', index=False)\n",
    "#         with open(\"proposed_answers.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "#             for idx, pred in enumerate(preds):\n",
    "#                 f.write(\"{}\\n\".format(pred))\n",
    "        #write_prediction(self.args, os.path.join(self.args.eval_dir, \"proposed_answers.txt\"), preds)\n",
    "    \n",
    "\n",
    "    def save_model(self):\n",
    "        # Save model checkpoint (Overwrite)\n",
    "        if not os.path.exists(self.model_dir):\n",
    "            os.makedirs(self.model_dir)\n",
    "        model_to_save = self.model.module if hasattr(self.model, \"module\") else self.model\n",
    "        model_to_save.save_pretrained(self.model_dir)\n",
    "\n",
    "        # Save training arguments together with the trained model\n",
    "        #torch.save(self.args, os.path.join(self.args.model_dir, \"training_args.bin\"))\n",
    "        logger.info(\"Saving model checkpoint to %s\", self.model_dir)\n",
    "\n",
    "    def load_model(self):\n",
    "        # Check whether model exists\n",
    "        if not os.path.exists(self.model_dir):\n",
    "            raise Exception(\"Model doesn't exists! Train first!\")\n",
    "\n",
    "        #self.args = torch.load(os.path.join(self.args.model_dir, \"training_args.bin\"))\n",
    "        self.model = RXLMRoberta.from_pretrained(self.model_dir)\n",
    "        self.model.to(self.device)\n",
    "        logger.info(\"***** Model Loaded *****\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdf1565f-1a5a-4def-9b07-b7a8d3611cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_logger():\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc40c6f-54df-444c-89c1-d4ac70d453a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = load_data(\"/opt/ml/input/data/train/train.tsv\")\n",
    "# test_dataset = load_data(\"/opt/ml/input/data/test/test.tsv\")\n",
    "# #dev_dataset = load_data(\"./dataset/train/dev.tsv\")\n",
    "# #train_label = train_dataset['label'].values\n",
    "# #train_dataset.columns= ['link','sentence' 'entity_01','e1s','e1e','entity_02','e2s','e2e','label']\n",
    "# ADDITIONAL_SPECIAL_TOKENS = [\"<e1>\", \"</e1>\", \"<e2>\", \"</e2>\"]\n",
    "# MODEL_NAME = \"xlm-roberta-large\"\n",
    "# #MODEL_NAME = \"xlm-roXLMRobertaa-large\"\n",
    "# tokenizer = XLMRobertaTokenizer.from_pretrained(MODEL_NAME)\n",
    "# tokenizer.add_special_tokens({\"additional_special_tokens\": ADDITIONAL_SPECIAL_TOKENS})\n",
    "# train_Dataset = convert_sentence_to_features(train_dataset, tokenizer, max_len = 339+2)\n",
    "# print(train_Dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac768df0-f7d8-4dce-aa7c-b32af573dda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_NAME = \"xlm-roberta-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "ADDITIONAL_SPECIAL_TOKENS = [\"#\", \"@\"]   \n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\": ADDITIONAL_SPECIAL_TOKENS})\n",
    "s = '용병 @ α CIVILIZATION α 공격수@ 챠디의 부진과 시즌 초 활약한 # β PERSON β 강수일#의 침체, 시즌 중반에 영입한 세르비아 출신 용병 미드필더 오그넨 코로만의 부상 등이 부진의 원인으로 지적되던 가운데 인천은 시즌 마지막 4경기에서 3승 1패를 거두며 막판 승점 쌓기에 성공, 정규리그 순위 5위로 플레이오프에 진출하는 데에 성공했다.'\n",
    "s = s.replace('α', '')\n",
    "s = s.replace('β', '')\n",
    "li = tokenizer.tokenize(s)\n",
    "print(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9dc1b1-76c8-4757-aa34-cf17e66a1a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_NAME = \"xlm-roberta-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "print(tokenizer(['안녕 만나서 반가워', '왜 이게 이렇게 나오지'],\n",
    "      return_tensors=\"pt\",\n",
    "      padding=True,\n",
    "      truncation=True,\n",
    "      max_length=100,\n",
    "      add_special_tokens=True,\n",
    "      return_token_type_ids=True,\n",
    "      ))\n",
    "ADDITIONAL_SPECIAL_TOKENS = [\"#\", \"@\", \"α\", \"β\"]\n",
    "      \n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\": ADDITIONAL_SPECIAL_TOKENS})\n",
    "tokenizer.tokenize('용병 @ α CIVILIZATION α 공격수@ 챠디의 부진과 시즌 초 활약한 # β PERSON β 강수일#의 침체, 시즌 중반에 영입한 세르비아 출신 용병 미드필더 오그넨 코로만의 부상 등이 부진의 원인으로 지적되던 가운데 인천은 시즌 마지막 4경기에서 3승 1패를 거두며 막판 승점 쌓기에 성공, 정규리그 순위 5위로 플레이오프에 진출하는 데에 성공했다.')\n",
    "train_Dataset = convert_sentence_to_features(['안녕 만나서 반가워', '왜 이게 이렇게 나오지'], tokenizer, max_len = 339+2)\n",
    "\n",
    "print(tokenizer.pad_token, tokenizer.pad_token_id)\n",
    "print(tokenizer.cls_token, tokenizer.cls_token_id)\n",
    "print(tokenizer.sep_token, tokenizer.sep_token_id)\n",
    "# load dataset\n",
    "train_dataset = load_data(\"/opt/ml/input/data/train/train.tsv\")\n",
    "#dev_dataset = load_data(\"./dataset/train/dev.tsv\")\n",
    "train_label = train_dataset['label'].values\n",
    "#dev_label = dev_dataset['label'].values\n",
    "\n",
    "\n",
    "tokenized_len_dataset = tokenized_dataset_len(train_dataset, tokenizer)\n",
    "print('최대 길이 : ', max(len(i) for i in tokenized_len_dataset))\n",
    "print('평균 길이 : ', sum(map(len, tokenized_len_dataset))/len(tokenized_len_dataset))\n",
    "plt.hist([len(s) for s in tokenized_len_dataset], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c16c05-f3bd-451c-9c6e-1ab30da8295e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"xlm-roberta-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "ADDITIONAL_SPECIAL_TOKENS = [\"<e1>\", \"</e1>\", \"<e2>\", \"</e2>\"] \n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\": ADDITIONAL_SPECIAL_TOKENS})\n",
    "\n",
    "train_dataset = load_data(\"/opt/ml/input/data/train/train.tsv\")\n",
    "train_label = train_dataset['label'].values\n",
    "\n",
    "for idx in tqdm(range(len(train_dataset))):\n",
    "    if train_dataset['e1s'][idx] > train_dataset['e2s'][idx]:\n",
    "        train_dataset['sentence'][idx] = train_dataset['sentence'][idx][:train_dataset['e2s'][idx]] + ' <e2> ' + train_dataset['sentence'][idx][train_dataset['e2s'][idx]:train_dataset['e2e'][idx]+1] + ' </e2> ' + train_dataset['sentence'][idx][train_dataset['e2e'][idx]+1:train_dataset['e1s'][idx]] + ' <e1> ' + train_dataset['sentence'][idx][train_dataset['e1s'][idx]:train_dataset['e1e'][idx]+1] + ' </e1> ' + train_dataset['sentence'][idx][train_dataset['e1e'][idx]+1:]          \n",
    "    else:\n",
    "        train_dataset['sentence'][idx] = train_dataset['sentence'][idx][:train_dataset['e1s'][idx]] + ' <e1> ' + train_dataset['sentence'][idx][train_dataset['e1s'][idx]:train_dataset['e1e'][idx]+1] + ' </e1> ' + train_dataset['sentence'][idx][train_dataset['e1e'][idx]+1:train_dataset['e2s'][idx]] + ' <e2> ' + train_dataset['sentence'][idx][train_dataset['e2s'][idx]:train_dataset['e2e'][idx]+1] + ' </e2> ' + train_dataset['sentence'][idx][train_dataset['e2e'][idx]+1:]              \n",
    "\n",
    "\n",
    "tokenized_len_dataset = tokenized_dataset_len(train_dataset, tokenizer)\n",
    "\n",
    "print('최대 길이 : ', max(len(i) for i in tokenized_len_dataset))\n",
    "print('평균 길이 : ', sum(map(len, tokenized_len_dataset))/len(tokenized_len_dataset))\n",
    "plt.hist([len(s) for s in tokenized_len_dataset], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3bab54-a7da-4d1f-ac47-36b69bdfd32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"xlm-roberta-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "ADDITIONAL_SPECIAL_TOKENS = [\"#\", \"@\", \"α\", \"β\"]   \n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\": ADDITIONAL_SPECIAL_TOKENS})\n",
    "\n",
    "train_dataset = load_data(\"/opt/ml/input/data/train/train.tsv\")\n",
    "li = [len(i) for i in tokenized_len_dataset]\n",
    "train_dataset['len'] = li\n",
    "\n",
    "train_dataset = train_dataset[train_dataset['len'] <= 250]\n",
    "train_dataset = train_dataset.reset_index(drop=False, inplace=False)\n",
    "del train_dataset['index']\n",
    "#train_dataset.head(57)\n",
    "#train_dataset.head()\n",
    "for idx in tqdm(range(len(train_dataset))):\n",
    "    if train_dataset['e1s'][idx] > train_dataset['e2s'][idx]:\n",
    "        train_dataset['sentence'][idx] = train_dataset['sentence'][idx][:train_dataset['e2s'][idx]] + ' <e2> ' + train_dataset['sentence'][idx][train_dataset['e2s'][idx]:train_dataset['e2e'][idx]+1] + ' </e2> ' + train_dataset['sentence'][idx][train_dataset['e2e'][idx]+1:train_dataset['e1s'][idx]] + ' <e1> ' + train_dataset['sentence'][idx][train_dataset['e1s'][idx]:train_dataset['e1e'][idx]+1] + ' </e1> ' + train_dataset['sentence'][idx][train_dataset['e1e'][idx]+1:]          \n",
    "    else:\n",
    "        train_dataset['sentence'][idx] = train_dataset['sentence'][idx][:train_dataset['e1s'][idx]] + ' <e1> ' + train_dataset['sentence'][idx][train_dataset['e1s'][idx]:train_dataset['e1e'][idx]+1] + ' </e1> ' + train_dataset['sentence'][idx][train_dataset['e1e'][idx]+1:train_dataset['e2s'][idx]] + ' <e2> ' + train_dataset['sentence'][idx][train_dataset['e2s'][idx]:train_dataset['e2e'][idx]+1] + ' </e2> ' + train_dataset['sentence'][idx][train_dataset['e2e'][idx]+1:]              \n",
    "\n",
    "\n",
    "tokenized_len_dataset = tokenized_dataset_len(train_dataset, tokenizer)\n",
    "\n",
    "print('최대 길이 : ', max(len(i) for i in tokenized_len_dataset))\n",
    "print('평균 길이 : ', sum(map(len, tokenized_len_dataset))/len(tokenized_len_dataset))\n",
    "plt.hist([len(s) for s in tokenized_len_dataset], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bbce9a-f2ef-4049-8ecd-7e52c26f713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"xlm-roberta-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "ADDITIONAL_SPECIAL_TOKENS = [\"#\", \"@\", \"α\", \"β\"]   \n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\": ADDITIONAL_SPECIAL_TOKENS})\n",
    "\n",
    "train_dataset = load_data(\"/opt/ml/input/data/train/ner_train_ver2.tsv\")\n",
    "# train_label = train_dataset['label'].values\n",
    "\n",
    "tokenized_len_dataset = tokenized_dataset_len(train_dataset, tokenizer)\n",
    "print('최대 길이 : ', max(len(i) for i in tokenized_len_dataset))\n",
    "print('평균 길이 : ', sum(map(len, tokenized_len_dataset))/len(tokenized_len_dataset))\n",
    "plt.hist([len(s) for s in tokenized_len_dataset], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6221073-169e-49c2-b58e-857d67e9bb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"xlm-roberta-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "ADDITIONAL_SPECIAL_TOKENS = [\"<e1>\", \"</e1>\", \"<e2>\", \"</e2>\"] \n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\": ADDITIONAL_SPECIAL_TOKENS})\n",
    "\n",
    "train_dataset = load_data(\"/opt/ml/input/data/train/ner_train_ver2.tsv\")\n",
    "train_label = train_dataset['label'].values\n",
    "\n",
    "for idx in tqdm(range(len(train_dataset))):\n",
    "    if train_dataset['e1s'][idx] > train_dataset['e2s'][idx]:\n",
    "        train_dataset['sentence'][idx] = train_dataset['sentence'][idx][:train_dataset['e2s'][idx]] + ' <e2> ' + train_dataset['sentence'][idx][train_dataset['e2s'][idx]:train_dataset['e2e'][idx]+1] + ' </e2> ' + train_dataset['sentence'][idx][train_dataset['e2e'][idx]+1:train_dataset['e1s'][idx]] + ' <e1> ' + train_dataset['sentence'][idx][train_dataset['e1s'][idx]:train_dataset['e1e'][idx]+1] + ' </e1> ' + train_dataset['sentence'][idx][train_dataset['e1e'][idx]+1:]          \n",
    "    else:\n",
    "        train_dataset['sentence'][idx] = train_dataset['sentence'][idx][:train_dataset['e1s'][idx]] + ' <e1> ' + train_dataset['sentence'][idx][train_dataset['e1s'][idx]:train_dataset['e1e'][idx]+1] + ' </e1> ' + train_dataset['sentence'][idx][train_dataset['e1e'][idx]+1:train_dataset['e2s'][idx]] + ' <e2> ' + train_dataset['sentence'][idx][train_dataset['e2s'][idx]:train_dataset['e2e'][idx]+1] + ' </e2> ' + train_dataset['sentence'][idx][train_dataset['e2e'][idx]+1:]              \n",
    "\n",
    "\n",
    "tokenized_len_dataset = tokenized_dataset_len(train_dataset, tokenizer)\n",
    "\n",
    "print('최대 길이 : ', max(len(i) for i in tokenized_len_dataset))\n",
    "print('평균 길이 : ', sum(map(len, tokenized_len_dataset))/len(tokenized_len_dataset))\n",
    "plt.hist([len(s) for s in tokenized_len_dataset], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df5b5510-0cc8-450d-90b0-2732a24a3f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "072caaf8c67c47f1b30fbca840468081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='tokenizing', max=9000.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a1453c074834edc877a0349d59de2a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='tokenizing', max=1000.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 00:22:32 - INFO - __main__ -   ***** Running training *****\n",
      "04/21/2021 00:22:32 - INFO - __main__ -     Num examples = 9000\n",
      "04/21/2021 00:22:32 - INFO - __main__ -     Num Epochs = 6\n",
      "04/21/2021 00:22:32 - INFO - __main__ -     Total train batch size = 16\n",
      "04/21/2021 00:22:32 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
      "04/21/2021 00:22:32 - INFO - __main__ -     Total optimization steps = 3378\n",
      "04/21/2021 00:22:32 - INFO - __main__ -     Logging steps = 400\n",
      "04/21/2021 00:22:32 - INFO - __main__ -     Save steps = 400\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c46b15e2287c4a958112c117d0966624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=6.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "463817eb1a4c497bb862bc0a0addc950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=563.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "04/21/2021 00:30:21 - INFO - __main__ -     global steps = 400\n",
      "04/21/2021 00:30:21 - INFO - __main__ -   ***** Running evaluation on train dataset *****\n",
      "04/21/2021 00:30:21 - INFO - __main__ -     Num examples = 9000\n",
      "04/21/2021 00:30:21 - INFO - __main__ -     Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c75331b809c7424b8e33ac5d2366c956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=563.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 00:33:47 - INFO - __main__ -   ***** Eval results *****\n",
      "04/21/2021 00:33:47 - INFO - __main__ -     acc = 0.7182\n",
      "04/21/2021 00:33:47 - INFO - __main__ -     loss = 0.9767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 00:34:25 - INFO - __main__ -   Saving model checkpoint to ./model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed55fa5bae54ef1941e95faf7f39da3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=563.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 00:42:14 - INFO - __main__ -     global steps = 800\n",
      "04/21/2021 00:42:14 - INFO - __main__ -   ***** Running evaluation on train dataset *****\n",
      "04/21/2021 00:42:14 - INFO - __main__ -     Num examples = 9000\n",
      "04/21/2021 00:42:14 - INFO - __main__ -     Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ace3cbc04e4767bf509eed8497035a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=563.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 00:45:40 - INFO - __main__ -   ***** Eval results *****\n",
      "04/21/2021 00:45:40 - INFO - __main__ -     acc = 0.7900\n",
      "04/21/2021 00:45:40 - INFO - __main__ -     loss = 0.6796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 00:46:17 - INFO - __main__ -   Saving model checkpoint to ./model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51660aab5ffe42589f70ab2f5b48ac5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=563.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 00:54:05 - INFO - __main__ -     global steps = 1200\n",
      "04/21/2021 00:54:05 - INFO - __main__ -   ***** Running evaluation on train dataset *****\n",
      "04/21/2021 00:54:05 - INFO - __main__ -     Num examples = 9000\n",
      "04/21/2021 00:54:05 - INFO - __main__ -     Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d19247c59c94aaeac2e9d62b2108ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=563.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 00:57:31 - INFO - __main__ -   ***** Eval results *****\n",
      "04/21/2021 00:57:31 - INFO - __main__ -     acc = 0.8381\n",
      "04/21/2021 00:57:31 - INFO - __main__ -     loss = 0.5338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 00:58:19 - INFO - __main__ -   Saving model checkpoint to ./model\n",
      "04/21/2021 01:06:07 - INFO - __main__ -     global steps = 1600\n",
      "04/21/2021 01:06:07 - INFO - __main__ -   ***** Running evaluation on train dataset *****\n",
      "04/21/2021 01:06:07 - INFO - __main__ -     Num examples = 9000\n",
      "04/21/2021 01:06:07 - INFO - __main__ -     Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b18d8d4ea9d4a02b0f8018de6eae924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=563.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 01:09:33 - INFO - __main__ -   ***** Eval results *****\n",
      "04/21/2021 01:09:33 - INFO - __main__ -     acc = 0.8909\n",
      "04/21/2021 01:09:33 - INFO - __main__ -     loss = 0.3705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 01:10:12 - INFO - __main__ -   Saving model checkpoint to ./model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eceb0bb224c74189b6fb4d3299d0d3e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=563.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 01:18:00 - INFO - __main__ -     global steps = 2000\n",
      "04/21/2021 01:18:00 - INFO - __main__ -   ***** Running evaluation on train dataset *****\n",
      "04/21/2021 01:18:00 - INFO - __main__ -     Num examples = 9000\n",
      "04/21/2021 01:18:00 - INFO - __main__ -     Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5828d2ac8e794ac6849ce96edd30f848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=563.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 01:21:25 - INFO - __main__ -   ***** Eval results *****\n",
      "04/21/2021 01:21:25 - INFO - __main__ -     acc = 0.9159\n",
      "04/21/2021 01:21:25 - INFO - __main__ -     loss = 0.2790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 01:22:03 - INFO - __main__ -   Saving model checkpoint to ./model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75cdd75d7e544ddea07d1a6598bc57bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=563.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 01:29:50 - INFO - __main__ -     global steps = 2400\n",
      "04/21/2021 01:29:50 - INFO - __main__ -   ***** Running evaluation on train dataset *****\n",
      "04/21/2021 01:29:50 - INFO - __main__ -     Num examples = 9000\n",
      "04/21/2021 01:29:50 - INFO - __main__ -     Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fafc6312161a46a5af86595966014b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=563.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 01:33:16 - INFO - __main__ -   ***** Eval results *****\n",
      "04/21/2021 01:33:16 - INFO - __main__ -     acc = 0.9458\n",
      "04/21/2021 01:33:16 - INFO - __main__ -     loss = 0.1951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 01:33:53 - INFO - __main__ -   Saving model checkpoint to ./model\n",
      "04/21/2021 01:41:41 - INFO - __main__ -     global steps = 2800\n",
      "04/21/2021 01:41:41 - INFO - __main__ -   ***** Running evaluation on train dataset *****\n",
      "04/21/2021 01:41:41 - INFO - __main__ -     Num examples = 9000\n",
      "04/21/2021 01:41:41 - INFO - __main__ -     Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f401433e0934633a6f1b048fbebe786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=563.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 01:45:07 - INFO - __main__ -   ***** Eval results *****\n",
      "04/21/2021 01:45:07 - INFO - __main__ -     acc = 0.9601\n",
      "04/21/2021 01:45:07 - INFO - __main__ -     loss = 0.1363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 01:45:44 - INFO - __main__ -   Saving model checkpoint to ./model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a6189d2741a4ec1bdce3ce9aa7956ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=563.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 01:53:32 - INFO - __main__ -     global steps = 3200\n",
      "04/21/2021 01:53:32 - INFO - __main__ -   ***** Running evaluation on train dataset *****\n",
      "04/21/2021 01:53:32 - INFO - __main__ -     Num examples = 9000\n",
      "04/21/2021 01:53:32 - INFO - __main__ -     Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac4b789a442b4b7787cb34ec957668e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=563.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 01:56:57 - INFO - __main__ -   ***** Eval results *****\n",
      "04/21/2021 01:56:57 - INFO - __main__ -     acc = 0.9700\n",
      "04/21/2021 01:56:57 - INFO - __main__ -     loss = 0.1070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/21/2021 01:57:35 - INFO - __main__ -   Saving model checkpoint to ./model\n",
      "04/21/2021 02:01:03 - INFO - __main__ -   ***** Running evaluation on test dataset *****\n",
      "04/21/2021 02:01:03 - INFO - __main__ -     Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13167f16921450ea5d110690aa8ba70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Predicting', max=63.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    init_logger()\n",
    "    #train_dataset = load_data(\"/opt/ml/input/data/train/train+all.tsv\")\n",
    "    train_dataset = load_data(\"/opt/ml/input/data/train/ner_train_ver2.tsv\")\n",
    "    \n",
    "    test_dataset = load_data(\"/opt/ml/input/data/test/ner_test_ver2.tsv\")\n",
    "    #dev_dataset = load_data(\"./dataset/train/dev.tsv\")\n",
    "    #train_label = train_dataset['label'].values\n",
    "    #train_dataset.columns= ['link','sentence' 'entity_01','e1s','e1e','entity_02','e2s','e2e','label']\n",
    "    ADDITIONAL_SPECIAL_TOKENS = [\"#\", \"@\", \"α\", \"β\"]\n",
    "    MODEL_NAME = \"xlm-roberta-large\"\n",
    "    #MODEL_NAME = \"xlm-roXLMRobertaa-large\"\n",
    "    tokenizer = XLMRobertaTokenizer.from_pretrained(MODEL_NAME)\n",
    "    tokenizer.add_special_tokens({\"additional_special_tokens\": ADDITIONAL_SPECIAL_TOKENS})\n",
    "    \n",
    "#     li = [len(i) for i in tokenized_len_dataset]\n",
    "#     train_dataset['len'] = li\n",
    "\n",
    "#     train_dataset = train_dataset[train_dataset['len'] <= 250]\n",
    "#     train_dataset = train_dataset.reset_index(drop=False, inplace=False)\n",
    "#     del train_dataset['index']\n",
    "    \n",
    "    \n",
    "    train_Dataset = convert_sentence_to_features(train_dataset, tokenizer, max_len = 351+2)\n",
    "    test_Dataset = convert_sentence_to_features(test_dataset, tokenizer, max_len=351+2)\n",
    "    with open('/opt/ml/input/data/label_type.pkl', 'rb') as f:\n",
    "        label_type = pickle.load(f)\n",
    "    \n",
    "    trainer = Trainer(eval_batch_size=16,train_batch_size=16, num_labels = 42,\n",
    "                      max_steps=-1, weight_decay=0.0, learning_rate= 2e-5, \n",
    "                      adam_epsilon=1e-8, warmup_steps=0, num_train_epochs=7,\n",
    "                      logging_steps=400, save_steps=400, max_grad_norm=1.0, \n",
    "                      model_dir='./model', gradient_accumulation_steps=1,dropout_rate = 0.1,\n",
    "                      label_dict=label_type,Model_name=MODEL_NAME,train_dataset=train_Dataset,\n",
    "                      test_dataset=test_Dataset)\n",
    "    \n",
    "    do_train = True\n",
    "    do_test = True\n",
    "    if do_train:\n",
    "        trainer.train()\n",
    "\n",
    "    if do_test:\n",
    "        trainer.test_pred()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d4e429-7676-46bd-bd6f-501782383863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a04a382-c41f-4e00-a047-cd128cc06f64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
